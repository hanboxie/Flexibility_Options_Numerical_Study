{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyomo.environ as pyo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime\n",
    "import ast\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DA model with Flexibility Options and Storage Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAFOModel:\n",
    "    def __init__(self, num_periods=24, num_scenarios=5, num_generators=0, num_tiers=4, num_storage=0):\n",
    "        self.num_periods = num_periods\n",
    "        self.num_scenarios = num_scenarios\n",
    "        self.num_generators = num_generators\n",
    "        self.num_tiers = num_tiers\n",
    "        self.num_storage = num_storage\n",
    "        \n",
    "        self.model = pyo.AbstractModel()\n",
    "        self._define_sets()\n",
    "        self._define_parameters()\n",
    "        self._define_variables()\n",
    "        self._define_objective()\n",
    "        self._define_constraints()\n",
    "    \n",
    "    def _define_sets(self):\n",
    "        self.model.T = pyo.RangeSet(1, self.num_periods)    # Set of time periods\n",
    "        self.model.S = pyo.RangeSet(1, self.num_scenarios)  # Set of scenarios\n",
    "        self.model.R = pyo.RangeSet(1, self.num_tiers)      # Set of tiers\n",
    "        \n",
    "        # Generator set\n",
    "        if self.num_generators > 0:\n",
    "            self.model.G = pyo.RangeSet(1, self.num_generators)\n",
    "        else:\n",
    "            self.model.G = pyo.Set()\n",
    "        \n",
    "        # Storage set\n",
    "        if self.num_storage > 0:\n",
    "            self.model.B = pyo.RangeSet(1, self.num_storage)\n",
    "        else:\n",
    "            self.model.B = pyo.Set()\n",
    "    \n",
    "    def _define_parameters(self):\n",
    "        # General Parameters\n",
    "        self.model.VC = pyo.Param(self.model.G)           # Variable cost\n",
    "        self.model.VCUP = pyo.Param(self.model.G)         # Variable cost up\n",
    "        self.model.VCDN = pyo.Param(self.model.G)         # Variable cost down\n",
    "        self.model.CAP = pyo.Param(self.model.G)          # Capacity\n",
    "        self.model.REDA = pyo.Param(self.model.T)         # Maximum DA RE for each hour\n",
    "        self.model.DEMAND = pyo.Param(self.model.T)       # Electricity demand per hour\n",
    "        self.model.D1 = pyo.Param(within=pyo.NonNegativeIntegers)    # Linear cost coefficient for demand slack\n",
    "        self.model.D2 = pyo.Param(within=pyo.NonNegativeIntegers)    # Quadratic cost coefficient for demand slack\n",
    "\n",
    "        # Parameters specific to the FO\n",
    "        self.model.RR = pyo.Param(self.model.G)                      # Ramp rate\n",
    "        self.model.RE = pyo.Param(self.model.S, self.model.T)        # Renewable generation at each scenario and time\n",
    "        self.model.PEN = pyo.Param(within=pyo.NonNegativeIntegers)   # Penalty for inadequate flexibility up\n",
    "        self.model.PENDN = pyo.Param(within=pyo.NonNegativeIntegers) # Penalty for inadequate flexibility down\n",
    "        self.model.smallM = pyo.Param(within=pyo.NonNegativeReals)   # Parameter for alternative optima\n",
    "        self.model.probTU = pyo.Param(self.model.R)                  # Probability of exercise FO up\n",
    "        self.model.probTD = pyo.Param(self.model.R)                  # Probability of exercise FO down\n",
    "\n",
    "        # Storage Parameters\n",
    "        self.model.E_MAX = pyo.Param(self.model.B)        # Maximum energy capacity\n",
    "        self.model.P_MAX = pyo.Param(self.model.B)        # Maximum power capacity\n",
    "        self.model.ETA_CH = pyo.Param(self.model.B)       # Charging efficiency\n",
    "        self.model.ETA_DCH = pyo.Param(self.model.B)      # Discharging efficiency\n",
    "        self.model.E0 = pyo.Param(self.model.B)           # Initial state of charge\n",
    "        self.model.E_FINAL = pyo.Param(self.model.B)      # Required final state of charge\n",
    "        self.model.STORAGE_COST = pyo.Param(self.model.B) # Storage operating cost per MWh\n",
    "    \n",
    "    def _define_variables(self):\n",
    "        # Energy and reserve variables\n",
    "        self.model.d = pyo.Var(self.model.T, domain=pyo.NonNegativeReals)      # Demand slack\n",
    "        self.model.rgDA = pyo.Var(self.model.T, domain=pyo.NonNegativeReals)   # DA renewables schedule\n",
    "        self.model.du = pyo.Var(self.model.S, self.model.T)                    # Demand uncertainty\n",
    "        \n",
    "        # Variables dependent on generator set\n",
    "        if len(self.model.G) > 0 or isinstance(self.model.G, pyo.RangeSet):\n",
    "            self.model.xDA = pyo.Var(self.model.G, self.model.T, domain=pyo.NonNegativeReals)  # DA energy schedule\n",
    "            # generator FO Variables\n",
    "            self.model.hsu = pyo.Var(self.model.R, self.model.G, self.model.T, domain=pyo.NonNegativeReals)  # Supply FO up\n",
    "            self.model.hsd = pyo.Var(self.model.R, self.model.G, self.model.T, domain=pyo.NonNegativeReals)  # Supply FO down\n",
    "            \n",
    "        # FO Variables independent of generators and storage\n",
    "        self.model.hdu = pyo.Var(self.model.R, self.model.T, domain=pyo.NonNegativeReals)     # Demand FO up\n",
    "        self.model.hdd = pyo.Var(self.model.R, self.model.T, domain=pyo.NonNegativeReals)     # Demand FO down\n",
    "        self.model.sdu = pyo.Var(self.model.R, self.model.T, domain=pyo.NonNegativeReals)     # Self-supply FO up\n",
    "        self.model.sdd = pyo.Var(self.model.R, self.model.T, domain=pyo.NonNegativeReals)     # Self-supply FO down\n",
    "        self.model.y = pyo.Var(self.model.S, self.model.T, domain=pyo.NonNegativeReals)       # Auxiliary variable\n",
    "\n",
    "        # Variables dependent on storage set\n",
    "        if len(self.model.B) > 0 or isinstance(self.model.B, pyo.RangeSet):\n",
    "            # Storage Variables\n",
    "            self.model.e = pyo.Var(self.model.B, self.model.T, domain=pyo.NonNegativeReals)     # Energy level\n",
    "            self.model.p_ch = pyo.Var(self.model.B, self.model.T, domain=pyo.NonNegativeReals)  # Charging power\n",
    "            self.model.p_dch = pyo.Var(self.model.B, self.model.T, domain=pyo.NonNegativeReals) # Discharging power\n",
    "            # Storage FO Variables\n",
    "            self.model.bsu = pyo.Var(self.model.R, self.model.B, self.model.T, domain=pyo.NonNegativeReals)  # Storage FO up\n",
    "            self.model.bsd = pyo.Var(self.model.R, self.model.B, self.model.T, domain=pyo.NonNegativeReals)  # Storage FO down\n",
    "    \n",
    "    def _define_objective(self):\n",
    "        # Objective function\n",
    "        def obj_expression(m):\n",
    "            objective_terms = []\n",
    "            \n",
    "            # objective_terms.append(sum(m.VC.get(g, 0) * m.xDA[g,t] \n",
    "            #                         for g in m.G for t in m.T \n",
    "            #                         if g in m.VC))\n",
    "        \n",
    "            \n",
    "            # Energy costs - generators\n",
    "            if hasattr(m, 'xDA') and len(m.G) > 0:\n",
    "                objective_terms.append(sum(m.VC[g] * m.xDA[g,t] for g in m.G for t in m.T))\n",
    "            \n",
    "            # Flexibility costs - generators\n",
    "            if hasattr(m, 'hsu') and len(m.G) > 0:\n",
    "                objective_terms.append(sum(m.probTU[r] * m.VCUP[g] * m.hsu[r,g,t] for g in m.G for r in m.R for t in m.T))\n",
    "                objective_terms.append(-sum(m.probTD[r] * m.VCDN[g] * m.hsd[r,g,t] for g in m.G for r in m.R for t in m.T))\n",
    "            \n",
    "            # Self-supply flexibility costs\n",
    "            objective_terms.append(sum(m.probTU[r] * m.PEN * m.sdu[r,t] for r in m.R for t in m.T))\n",
    "            objective_terms.append(-sum(m.probTD[r] * m.PENDN * m.sdd[r,t] for r in m.R for t in m.T))\n",
    "            \n",
    "            # Storage related costs\n",
    "            if hasattr(m, 'bsu') and len(m.B) > 0:\n",
    "                # Storage flexibility costs\n",
    "                objective_terms.append(sum(m.probTU[r] * m.STORAGE_COST[b] * m.bsu[r,b,t] for b in m.B for r in m.R for t in m.T))\n",
    "                objective_terms.append(-sum(m.probTD[r] * m.STORAGE_COST[b] * m.bsd[r,b,t] for b in m.B for r in m.R for t in m.T))\n",
    "                # Storage operation costs\n",
    "                objective_terms.append(sum(m.STORAGE_COST[b] * (m.p_ch[b,t] + m.p_dch[b,t]) for b in m.B for t in m.T))\n",
    "            \n",
    "            # Auxiliary costs\n",
    "            objective_terms.append(sum(m.y[s,t] for s in m.S for t in m.T) * m.smallM)\n",
    "            \n",
    "            # Demand response costs\n",
    "            objective_terms.append(sum(0.2 * m.D1 * (m.d[t] + m.du[s,t]) for s in m.S for t in m.T))\n",
    "            objective_terms.append(0.2 * m.D2 * sum((m.d[t] + m.du[s,t]) * (m.d[t] + m.du[s,t]) for s in m.S for t in m.T))\n",
    "            \n",
    "            return sum(objective_terms)\n",
    "\n",
    "        self.model.OBJ = pyo.Objective(rule=obj_expression)\n",
    "    \n",
    "    def _define_constraints(self):\n",
    "        # Define constraints - Numbering of constraints follows paper\n",
    "        # Energy balance for each hour\n",
    "        def DA_energy_balance(model, t):\n",
    "            gen_sum = 0\n",
    "            storage_sum = 0\n",
    "            \n",
    "            if hasattr(model, 'xDA'):\n",
    "                gen_sum = sum(model.xDA[g,t] for g in model.G) if len(model.G) > 0 else 0\n",
    "                \n",
    "            if hasattr(model, 'p_dch') and hasattr(model, 'p_ch'):\n",
    "                storage_sum = sum(model.p_dch[b,t] - model.p_ch[b,t] for b in model.B) if len(model.B) > 0 else 0\n",
    "            \n",
    "            return (gen_sum + \n",
    "                    model.rgDA[t] + \n",
    "                    storage_sum + \n",
    "                    model.d[t] == model.DEMAND[t])\n",
    "        \n",
    "        self.model.Con3 = pyo.Constraint(self.model.T, rule=DA_energy_balance)\n",
    "\n",
    "        # # Flexibility balance for each hour\n",
    "        # def DA_flexup_balance(model, r, t):\n",
    "        #     gen_flex_up = 0\n",
    "        #     storage_flex_up = 0\n",
    "            \n",
    "        #     if hasattr(model, 'hsu'):\n",
    "        #         gen_flex_up = sum(model.hsu[r,g,t] for g in model.G) if len(model.G) > 0 else 0\n",
    "                \n",
    "        #     if hasattr(model, 'bsu'):\n",
    "        #         storage_flex_up = sum(model.bsu[r,b,t] for b in model.B) if len(model.B) > 0 else 0\n",
    "            \n",
    "        #     return (gen_flex_up + storage_flex_up == model.hdu[r,t])\n",
    "        \n",
    "        # self.model.Con4UP = pyo.Constraint(self.model.R, self.model.T, rule=DA_flexup_balance)\n",
    "\n",
    "        # def DA_flexdn_balance(model, r, t):\n",
    "        #     gen_flex_down = 0\n",
    "        #     storage_flex_down = 0\n",
    "            \n",
    "        #     if hasattr(model, 'hsd'):\n",
    "        #         gen_flex_down = sum(model.hsd[r,g,t] for g in model.G) if len(model.G) > 0 else 0\n",
    "                \n",
    "        #     if hasattr(model, 'bsd'):\n",
    "        #         storage_flex_down = sum(model.bsd[r,b,t] for b in model.B) if len(model.B) > 0 else 0\n",
    "            \n",
    "        #     return (gen_flex_down + storage_flex_down == model.hdd[r,t])\n",
    "        \n",
    "        # self.model.Con4DN = pyo.Constraint(self.model.R, self.model.T, rule=DA_flexdn_balance)\n",
    "\n",
    "        # # Flexibility demand for each scenario and hour\n",
    "        # def DA_flex_demand(model, s, t):\n",
    "        #     return (-model.du[s,t] + \n",
    "        #             sum(model.hdd[r,t] + model.sdd[r,t] for r in model.R if r <= s-1) -\n",
    "        #             sum(model.hdu[r,t] + model.sdu[r,t] for r in model.R if r >= s) == \n",
    "        #             model.RE[s,t] - model.rgDA[t])\n",
    "        \n",
    "        # self.model.Con6 = pyo.Constraint(self.model.S, self.model.T, rule=DA_flex_demand)\n",
    "\n",
    "        # # Add generator constraints only if generators exist\n",
    "        # if hasattr(self.model, 'xDA') and (len(self.model.G) > 0 or isinstance(self.model.G, pyo.RangeSet) or self.num_generators is None):\n",
    "        #     # Inter-temporal constraints\n",
    "        #     def ramp_rate_up(model, g, t):\n",
    "        #         if t == 1:\n",
    "        #             return pyo.Constraint.Skip\n",
    "        #         return model.xDA[g,t] - model.xDA[g,t-1] <= model.RR[g]\n",
    "            \n",
    "        #     self.model.ramp_up = pyo.Constraint(self.model.G, self.model.T, rule=ramp_rate_up)\n",
    "\n",
    "        #     def ramp_rate_down(model, g, t):\n",
    "        #         if t == 1:\n",
    "        #             return pyo.Constraint.Skip\n",
    "        #         return model.xDA[g,t-1] - model.xDA[g,t] <= model.RR[g]\n",
    "            \n",
    "        #     self.model.ramp_down = pyo.Constraint(self.model.G, self.model.T, rule=ramp_rate_down)\n",
    "\n",
    "        #     # Generation limits without commitment status\n",
    "        #     def generation_limits(model, g, t):\n",
    "        #         return model.xDA[g,t] <= model.CAP[g]\n",
    "            \n",
    "        #     self.model.generation_limits = pyo.Constraint(self.model.G, self.model.T, rule=generation_limits)\n",
    "\n",
    "        # # Add storage constraints only if storage exists\n",
    "        # if hasattr(self.model, 'e') and (len(self.model.B) > 0 or isinstance(self.model.B, pyo.RangeSet) or self.num_storage is None):\n",
    "        #     # Storage energy balance\n",
    "        #     def storage_balance(model, b, t):\n",
    "        #         if t == 1:\n",
    "        #             return (model.e[b,t] == model.E0[b] + \n",
    "        #                     model.ETA_CH[b] * model.p_ch[b,t] - \n",
    "        #                     (1/model.ETA_DCH[b]) * model.p_dch[b,t])\n",
    "        #         else:\n",
    "        #             return (model.e[b,t] == model.e[b,t-1] + \n",
    "        #                     model.ETA_CH[b] * model.p_ch[b,t] - \n",
    "        #                     (1/model.ETA_DCH[b]) * model.p_dch[b,t])\n",
    "\n",
    "        # Record duals for market analysis\n",
    "        self.model.dual = pyo.Suffix(direction=pyo.Suffix.IMPORT)\n",
    "        \n",
    "    def create_instance(self, data):\n",
    "        return self.model.create_instance(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RT Simulation Model with Storage Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RTSimModel:\n",
    "    def __init__(self, num_periods=24, num_scenarios=5, num_generators=None, num_storage=None):\n",
    "        self.num_periods = num_periods\n",
    "        self.num_scenarios = num_scenarios\n",
    "        self.num_generators = num_generators\n",
    "        self.num_storage = num_storage\n",
    "        \n",
    "        self.model = pyo.AbstractModel()\n",
    "        self._define_sets()\n",
    "        self._define_parameters()\n",
    "        self._define_variables()\n",
    "        self._define_objective()\n",
    "        self._define_constraints()\n",
    "    \n",
    "    def _define_sets(self):\n",
    "        # Sets\n",
    "        self.model.T = pyo.RangeSet(1, self.num_periods)    # Set of time periods\n",
    "        self.model.S = pyo.RangeSet(1, self.num_scenarios)  # Set of scenarios\n",
    "        \n",
    "        # Generator set - can be determined from data\n",
    "        if self.num_generators is not None and self.num_generators > 0:\n",
    "            self.model.G = pyo.RangeSet(1, self.num_generators)\n",
    "        else:\n",
    "            self.model.G = pyo.Set()  # Will be populated when data is loaded or can be empty\n",
    "        \n",
    "        # Storage set - can be determined from data\n",
    "        if self.num_storage is not None and self.num_storage > 0:\n",
    "            self.model.B = pyo.RangeSet(1, self.num_storage)\n",
    "        else:\n",
    "            self.model.B = pyo.Set()  # Will be populated when data is loaded or can be empty\n",
    "    \n",
    "    def _define_parameters(self):\n",
    "        # Original Parameters\n",
    "        self.model.VC = pyo.Param(self.model.G)           # Variable cost\n",
    "        self.model.VCUP = pyo.Param(self.model.G)         # Variable cost up\n",
    "        self.model.VCDN = pyo.Param(self.model.G)         # Variable cost down\n",
    "        self.model.CAP = pyo.Param(self.model.G)          # Generator capacity\n",
    "        self.model.RR = pyo.Param(self.model.G)           # Ramp rate\n",
    "\n",
    "        self.model.prob = pyo.Param(self.model.S)         # Scenario probability\n",
    "        self.model.RE = pyo.Param(self.model.S, self.model.T)  # Renewable generation by scenario and time\n",
    "        self.model.DEMAND = pyo.Param(self.model.T)       # Hourly demand\n",
    "        self.model.D1 = pyo.Param(within=pyo.NonNegativeIntegers)  # Linear demand cost coefficient\n",
    "        self.model.D2 = pyo.Param(within=pyo.NonNegativeIntegers)  # Quadratic demand cost coefficient\n",
    "        self.model.xDA = pyo.Param(self.model.G, self.model.T) # DA schedule by generator and time\n",
    "        self.model.REDA = pyo.Param(self.model.T)         # DA renewable schedule by time\n",
    "        self.model.PEN = pyo.Param(within=pyo.NonNegativeIntegers)   # Upward penalty\n",
    "        self.model.PENDN = pyo.Param()                    # Downward penalty\n",
    "        self.model.DAdr = pyo.Param(self.model.T)         # DA demand response by time\n",
    "\n",
    "        # Storage Parameters\n",
    "        self.model.E_MAX = pyo.Param(self.model.B)        # Maximum energy capacity\n",
    "        self.model.P_MAX = pyo.Param(self.model.B)        # Maximum power capacity\n",
    "        self.model.ETA_CH = pyo.Param(self.model.B)       # Charging efficiency\n",
    "        self.model.ETA_DCH = pyo.Param(self.model.B)      # Discharging efficiency\n",
    "        self.model.E0 = pyo.Param(self.model.B)           # Initial state of charge\n",
    "        self.model.STORAGE_COST = pyo.Param(self.model.B)  # Operating cost per MWh of throughput\n",
    "        self.model.E_FINAL = pyo.Param(self.model.B)      # Required final state of charge\n",
    "        \n",
    "        # Storage DA parameters\n",
    "        self.model.e_DA = pyo.Param(self.model.B, self.model.T)  # DA energy level\n",
    "        self.model.p_ch_DA = pyo.Param(self.model.B, self.model.T)  # DA charging\n",
    "        self.model.p_dch_DA = pyo.Param(self.model.B, self.model.T)  # DA discharging\n",
    "    \n",
    "    def _define_variables(self):\n",
    "        # Variables that depend on generators\n",
    "        if len(self.model.G) > 0 or isinstance(self.model.G, pyo.RangeSet) or self.num_generators is None:\n",
    "            # RT adjustment variables for each scenario and time\n",
    "            self.model.xup = pyo.Var(self.model.S, self.model.G, self.model.T, domain=pyo.NonNegativeReals)  # Generator up adjustment\n",
    "            self.model.xdn = pyo.Var(self.model.S, self.model.G, self.model.T, domain=pyo.NonNegativeReals)  # Generator down adjustment\n",
    "        \n",
    "        # Variables independent of generators and storage\n",
    "        self.model.d = pyo.Var(self.model.S, self.model.T)     # RT demand response\n",
    "        self.model.rgup = pyo.Var(self.model.S, self.model.T, domain=pyo.NonNegativeReals)  # RE up adjustment\n",
    "        self.model.rgdn = pyo.Var(self.model.S, self.model.T, domain=pyo.NonNegativeReals)  # RE down adjustment\n",
    "        self.model.sdup = pyo.Var(self.model.S, self.model.T, domain=pyo.NonNegativeReals)  # Shortage\n",
    "        self.model.sddn = pyo.Var(self.model.S, self.model.T, domain=pyo.NonNegativeReals)  # Surplus\n",
    "\n",
    "        # Variables that depend on storage\n",
    "        if len(self.model.B) > 0 or isinstance(self.model.B, pyo.RangeSet) or self.num_storage is None:\n",
    "            # Storage Variables\n",
    "            self.model.e = pyo.Var(self.model.S, self.model.B, self.model.T, domain=pyo.NonNegativeReals)     # Energy level\n",
    "            self.model.p_ch = pyo.Var(self.model.S, self.model.B, self.model.T, domain=pyo.NonNegativeReals)  # Charging power\n",
    "            self.model.p_dch = pyo.Var(self.model.S, self.model.B, self.model.T, domain=pyo.NonNegativeReals) # Discharging power\n",
    "            self.model.b_up = pyo.Var(self.model.S, self.model.B, self.model.T, domain=pyo.NonNegativeReals)  # Storage up adjustment\n",
    "            self.model.b_dn = pyo.Var(self.model.S, self.model.B, self.model.T, domain=pyo.NonNegativeReals)  # Storage down adjustment\n",
    "    \n",
    "    def _define_objective(self):\n",
    "        # Objective Function\n",
    "        def obj_expression(m):\n",
    "            objective_terms = []\n",
    "            \n",
    "            for s in m.S:\n",
    "                scenario_terms = []\n",
    "                \n",
    "                # Generator adjustment costs - only if generators exist\n",
    "                if hasattr(m, 'xup') and len(m.G) > 0:\n",
    "                    scenario_terms.append(\n",
    "                        sum(m.VCUP[g] * m.xup[s,g,t] - m.VCDN[g] * m.xdn[s,g,t] for g in m.G for t in m.T)\n",
    "                    )\n",
    "                \n",
    "                # Shortage/surplus penalties\n",
    "                scenario_terms.append(m.PENDN * sum(m.sdup[s,t] for t in m.T))\n",
    "                scenario_terms.append(m.PEN * sum(m.sddn[s,t] for t in m.T))\n",
    "                \n",
    "                # Demand response costs\n",
    "                scenario_terms.append(\n",
    "                    sum((m.D1 * (m.DAdr[t] + m.d[s,t]) + \n",
    "                         m.D2 * (m.DAdr[t] + m.d[s,t]) * (m.DAdr[t] + m.d[s,t])) for t in m.T)\n",
    "                )\n",
    "                scenario_terms.append(\n",
    "                    -sum((m.D1 * m.DAdr[t] + m.D2 * m.DAdr[t] * m.DAdr[t]) for t in m.T)\n",
    "                )\n",
    "                \n",
    "                # Storage operating costs - only if storage exists\n",
    "                if hasattr(m, 'p_ch') and len(m.B) > 0:\n",
    "                    scenario_terms.append(\n",
    "                        sum(m.STORAGE_COST[b] * (m.p_ch[s,b,t] + m.p_dch[s,b,t]) for b in m.B for t in m.T)\n",
    "                    )\n",
    "                \n",
    "                # Add the weighted scenario terms to the overall objective\n",
    "                objective_terms.append(m.prob[s] * sum(scenario_terms))\n",
    "            \n",
    "            return sum(objective_terms)\n",
    "\n",
    "        self.model.OBJ = pyo.Objective(rule=obj_expression)\n",
    "    \n",
    "    def _define_constraints(self):\n",
    "        # RT energy balance for each scenario and time period\n",
    "        def RT_energy_balance(model, s, t):\n",
    "            gen_adjustment = 0\n",
    "            storage_adjustment = 0\n",
    "            \n",
    "            # Generator adjustments - only if generators exist\n",
    "            if hasattr(model, 'xup') and len(model.G) > 0:\n",
    "                gen_adjustment = sum(model.xup[s,g,t] - model.xdn[s,g,t] for g in model.G)\n",
    "            \n",
    "            # Storage adjustments - only if storage exists\n",
    "            if hasattr(model, 'p_ch') and len(model.B) > 0:\n",
    "                storage_adjustment = sum(\n",
    "                    model.p_dch[s,b,t] - model.p_ch[s,b,t] - \n",
    "                    model.p_dch_DA[b,t] + model.p_ch_DA[b,t] for b in model.B\n",
    "                )\n",
    "            \n",
    "            return (gen_adjustment +\n",
    "                    model.rgup[s,t] - model.rgdn[s,t] +\n",
    "                    storage_adjustment +\n",
    "                    model.d[s,t] == 0)\n",
    "                    \n",
    "        self.model.Con3 = pyo.Constraint(self.model.S, self.model.T, rule=RT_energy_balance)\n",
    "\n",
    "        # RT renewable availability\n",
    "        def RT_RE_availability(model, s, t):\n",
    "            return (model.rgup[s,t] - model.rgdn[s,t] + model.sdup[s,t] - model.sddn[s,t] == \n",
    "                    model.RE[s,t] - model.REDA[t])\n",
    "                    \n",
    "        self.model.Con4 = pyo.Constraint(self.model.S, self.model.T, rule=RT_RE_availability)\n",
    "\n",
    "        # Generator constraints - only if generators exist\n",
    "        if hasattr(self.model, 'xup') and (len(self.model.G) > 0 or isinstance(self.model.G, pyo.RangeSet) or self.num_generators is None):\n",
    "            # Generator ramping constraints\n",
    "            def RT_ramp_up(model, s, g, t):\n",
    "                return model.xup[s,g,t] <= model.RR[g]\n",
    "                \n",
    "            self.model.Con5up = pyo.Constraint(self.model.S, self.model.G, self.model.T, rule=RT_ramp_up)\n",
    "\n",
    "            def RT_ramp_dn(model, s, g, t):\n",
    "                return model.xdn[s,g,t] <= model.RR[g]\n",
    "                \n",
    "            self.model.Con5dn = pyo.Constraint(self.model.S, self.model.G, self.model.T, rule=RT_ramp_dn)\n",
    "\n",
    "            # Generator capacity constraints\n",
    "            def RT_capacity_cons(model, s, g, t):\n",
    "                return model.xDA[g,t] + model.xup[s,g,t] <= model.CAP[g]\n",
    "                \n",
    "            self.model.Con6 = pyo.Constraint(self.model.S, self.model.G, self.model.T, rule=RT_capacity_cons)\n",
    "\n",
    "            def RT_capacity_min(model, s, g, t):\n",
    "                return model.xDA[g,t] - model.xdn[s,g,t] >= 0\n",
    "                \n",
    "            self.model.Con7 = pyo.Constraint(self.model.S, self.model.G, self.model.T, rule=RT_capacity_min)\n",
    "\n",
    "        # Storage Constraints - only if storage exists\n",
    "        if hasattr(self.model, 'e') and (len(self.model.B) > 0 or isinstance(self.model.B, pyo.RangeSet) or self.num_storage is None):\n",
    "            # Storage energy balance\n",
    "            def storage_balance(model, s, b, t):\n",
    "                if t == 1:\n",
    "                    return (model.e[s,b,t] == model.E0[b] + \n",
    "                            model.ETA_CH[b] * model.p_ch[s,b,t] - \n",
    "                            (1/model.ETA_DCH[b]) * model.p_dch[s,b,t])\n",
    "                return (model.e[s,b,t] == model.e[s,b,t-1] + \n",
    "                        model.ETA_CH[b] * model.p_ch[s,b,t] - \n",
    "                        (1/model.ETA_DCH[b]) * model.p_dch[s,b,t])\n",
    "                        \n",
    "            self.model.storage_balance = pyo.Constraint(self.model.S, self.model.B, self.model.T, rule=storage_balance)\n",
    "\n",
    "            # Storage capacity constraint\n",
    "            def storage_capacity(model, s, b, t):\n",
    "                return model.e[s,b,t] <= model.E_MAX[b]\n",
    "                \n",
    "            self.model.storage_capacity = pyo.Constraint(self.model.S, self.model.B, self.model.T, rule=storage_capacity)\n",
    "\n",
    "            # Power limits\n",
    "            def power_limits(model, s, b, t):\n",
    "                return model.p_ch[s,b,t] + model.p_dch[s,b,t] <= model.P_MAX[b]\n",
    "                \n",
    "            self.model.power_limits = pyo.Constraint(self.model.S, self.model.B, self.model.T, rule=power_limits)\n",
    "            \n",
    "            # Storage adjustment limits\n",
    "            def storage_adjustment_limits(model, s, b, t):\n",
    "                return model.b_up[s,b,t] + model.b_dn[s,b,t] <= 0.5 * model.P_MAX[b]\n",
    "                \n",
    "            self.model.storage_adjustment_limits = pyo.Constraint(self.model.S, self.model.B, self.model.T, \n",
    "                                                                rule=storage_adjustment_limits)\n",
    "\n",
    "            # Final state of charge requirement\n",
    "            def final_soc(model, s, b):\n",
    "                return model.e[s,b,self.num_periods] >= model.E_FINAL[b]\n",
    "                \n",
    "            self.model.final_soc = pyo.Constraint(self.model.S, self.model.B, rule=final_soc)\n",
    "\n",
    "            # Storage ramping constraints\n",
    "            def storage_ramp_rate(model, s, b, t):\n",
    "                if t == 1:\n",
    "                    return pyo.Constraint.Skip\n",
    "                # This constraint with 'abs' needs to be reformulated for a solver\n",
    "                # Here's a simple reformulation with two constraints\n",
    "                return [\n",
    "                    model.p_ch[s,b,t] - model.p_ch[s,b,t-1] <= 0.25 * model.P_MAX[b],\n",
    "                    model.p_ch[s,b,t-1] - model.p_ch[s,b,t] <= 0.25 * model.P_MAX[b],\n",
    "                    model.p_dch[s,b,t] - model.p_dch[s,b,t-1] <= 0.25 * model.P_MAX[b],\n",
    "                    model.p_dch[s,b,t-1] - model.p_dch[s,b,t] <= 0.25 * model.P_MAX[b]\n",
    "                ]\n",
    "                        \n",
    "            self.model.storage_ramp = pyo.Constraint(self.model.S, self.model.B, self.model.T, rule=storage_ramp_rate)\n",
    "\n",
    "        # Record duals\n",
    "        self.model.dual = pyo.Suffix(direction=pyo.Suffix.IMPORT)\n",
    "        \n",
    "    def create_instance(self, data):\n",
    "        return self.model.create_instance(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SystemDataProcessor:\n",
    "    def __init__(self, gen_csv_path, storage_csv_path, demand_csv_path):\n",
    "        self.gen_csv_path = gen_csv_path\n",
    "        self.storage_csv_path = storage_csv_path\n",
    "        self.demand_csv_path = demand_csv_path\n",
    "        self.gen_data = None\n",
    "        self.storage_data = None\n",
    "        self.demand_data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        try:\n",
    "            self.gen_data = pd.read_csv(self.gen_csv_path).head(5)\n",
    "            self.storage_data = pd.read_csv(self.storage_csv_path).head(5)\n",
    "            print(f\"Generator and Storage data loaded successfully. {len(self.gen_data)} generators and {len(self.storage_data)} storages found.\")\n",
    "            self.demand_data = pd.read_csv(self.demand_csv_path)\n",
    "            print(f\"Demand data loaded successfully. {len(self.demand_data)} periods found.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def process_gen_data(self):\n",
    "        id_col = 'GEN UID'\n",
    "        column_mapping = {\n",
    "            # 'Ramp Rate MW/Min': '', \n",
    "            # 'Fuel Price $/MMBTU': '', \n",
    "            # 'VOM': '',\n",
    "            'PMax MW': 'CAP',\n",
    "            'Ramp Rate MW/Min': 'RR',\n",
    "        }\n",
    "\n",
    "        relevant_cols = list(column_mapping.keys())\n",
    "        existing_cols = [col for col in relevant_cols if col in self.gen_data.columns]\n",
    "        selected_cols = [id_col] + existing_cols\n",
    "        gen_data_filtered = self.gen_data[selected_cols].copy()\n",
    "\n",
    "        rename_dict = {col: column_mapping[col] for col in column_mapping if col in gen_data_filtered.columns}\n",
    "        gen_data_filtered.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "        original_ids = gen_data_filtered[id_col].tolist()\n",
    "        gen_id_mapping = {original_id: i+1 for i, original_id in enumerate(original_ids)}\n",
    "        gen_data_filtered[id_col] = gen_data_filtered[id_col].map(gen_id_mapping)\n",
    "        \n",
    "        gen_data_filtered.set_index(id_col, inplace=True)\n",
    "\n",
    "        # if 'Fuel Price $/MMBTU' in gen_data_filtered.columns and 'HR_avg_0' in self.gen_data.columns:\n",
    "        #     gen_data_filtered['VC'] = self.gen_data['Fuel Price $/MMBTU'] * self.gen_data['HR_avg_0'] / 1000.0\n",
    "        #     if 'VOM' in gen_data_filtered.columns:\n",
    "        #         gen_data_filtered['VC'] += gen_data_filtered['VOM']\n",
    "        \n",
    "        # TODO - CALCULATE VC, VCUP, VCDN\n",
    "        gen_data_filtered['VC'] = 20\n",
    "        gen_data_filtered['VCUP'] = 20\n",
    "        gen_data_filtered['VCDN'] = 20\n",
    "\n",
    "        params = ['CAP', 'RR','VC','VCUP','VCDN']\n",
    "        gen_data_dict = {}\n",
    "\n",
    "        for param in params:\n",
    "            if param in gen_data_filtered.columns:\n",
    "                param_dict = {}\n",
    "                for gen_idx in gen_data_filtered.index:\n",
    "                    param_dict[gen_idx] = gen_data_filtered.loc[gen_idx, param]\n",
    "                gen_data_dict[param] = param_dict\n",
    "            \n",
    "        return gen_data_dict\n",
    "\n",
    "    def process_storage_data(self):\n",
    "        if self.storage_data is None or self.storage_data.empty:\n",
    "            return {}\n",
    "            \n",
    "        try:\n",
    "            id_col = 'GEN UID'\n",
    "\n",
    "            column_mapping = {\n",
    "                'Max Volume GWh': 'E_MAX',\n",
    "                'Rating MVA': 'P_MAX',\n",
    "                'Initial Volume GWh': 'E0',\n",
    "                # 'Storage Roundtrip Efficiency': 'ETA'\n",
    "            }\n",
    "\n",
    "            relevant_cols = list(column_mapping.keys())\n",
    "            existing_cols = [col for col in relevant_cols if col in self.storage_data.columns]\n",
    "                \n",
    "            selected_cols = [id_col] + existing_cols\n",
    "            storage_data_filtered = self.storage_data[selected_cols].copy()\n",
    "\n",
    "            rename_dict = {col: column_mapping[col] for col in column_mapping if col in storage_data_filtered.columns}\n",
    "            storage_data_filtered.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "            original_ids = storage_data_filtered[id_col].tolist()\n",
    "            storage_id_mapping = {original_id: i+1 for i, original_id in enumerate(original_ids)}\n",
    "            storage_data_filtered[id_col] = storage_data_filtered[id_col].map(storage_id_mapping)\n",
    "        \n",
    "            storage_data_filtered.set_index(id_col, inplace=True)\n",
    "\n",
    "            storage_data_dict = {}\n",
    "\n",
    "            if 'E_MAX' in storage_data_filtered.columns:\n",
    "                storage_data_dict['E_MAX'] = {\n",
    "                    storage_idx: float(storage_data_filtered.at[storage_idx, 'E_MAX']) * 1000.0  # GWh to MWh\n",
    "                    for storage_idx in storage_data_filtered.index\n",
    "                }\n",
    "                \n",
    "            if 'P_MAX' in storage_data_filtered.columns:\n",
    "                storage_data_dict['P_MAX'] = {\n",
    "                    storage_idx: float(storage_data_filtered.loc[storage_idx, 'P_MAX'])\n",
    "                    for storage_idx in storage_data_filtered.index\n",
    "                }\n",
    "            \n",
    "            # check charging and discharging efficiency\n",
    "            storage_data_dict['ETA_CH'] = {\n",
    "                storage_idx: 0.9    \n",
    "                for storage_idx in storage_data_filtered.index\n",
    "            }\n",
    "            storage_data_dict['ETA_DCH'] = {\n",
    "                storage_idx: 0.9\n",
    "                for storage_idx in storage_data_filtered.index\n",
    "            }\n",
    "            storage_data_dict['STORAGE_COST'] = {\n",
    "                storage_idx: 0.9\n",
    "                for storage_idx in storage_data_filtered.index\n",
    "            }\n",
    "            storage_data_dict['E0'] = {\n",
    "                storage_idx: 0.0\n",
    "                for storage_idx in storage_data_filtered.index\n",
    "            }\n",
    "            storage_data_dict['E_FINAL'] = {\n",
    "                storage_idx: 0.0\n",
    "                for storage_idx in storage_data_filtered.index\n",
    "            }\n",
    "\n",
    "            # if 'E0' in storage_data_filtered.columns:\n",
    "            #     storage_data_dict['E0'] = {\n",
    "            #         storage_idx: float(storage_data_filtered.loc[old_idx, 'E0']) * 1000.0  # GWh to MWh\n",
    "            #         for old_idx, storage_idx in storage_indices.items()\n",
    "            #     }\n",
    "\n",
    "            return storage_data_dict\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing storage data: {str(e)}\")\n",
    "            return {}\n",
    "    \n",
    "    def process_demand_data(self, num_periods=24):\n",
    "        try:\n",
    "            demand_data = self.demand_data.head(num_periods)\n",
    "            demand_dict = demand_data.set_index(demand_data.index + 1)['1'].to_dict()\n",
    "            return demand_dict\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing demand data: {str(e)}\")\n",
    "            return {}     \n",
    "\n",
    "    def prepare_pyomo_data(self, num_periods=24, num_scenarios=5, num_tiers=4):\n",
    "        \"\"\"Prepare the data for the Pyomo model.\"\"\"\n",
    "        if self.gen_data is None:\n",
    "            success = self.load_data()\n",
    "            if not success:\n",
    "                return None\n",
    "                \n",
    "        gen_data_dict = self.process_gen_data()\n",
    "        storage_data_dict = self.process_storage_data()\n",
    "        demand_data_dict = self.process_demand_data(num_periods)\n",
    "        \n",
    "        num_generators = len(gen_data_dict.get('CAP', {}))\n",
    "        num_storage = len(storage_data_dict.get('E_MAX', {}))\n",
    "        \n",
    "        sets = {\n",
    "            # 'T': {None: list(range(1, num_periods + 1))},\n",
    "            'S': {None: list(range(1, num_scenarios + 1))},\n",
    "            'G': {None: list(range(1, num_generators + 1))},\n",
    "            'R': {None: list(range(1, num_tiers + 1))},\n",
    "            'B': {None: list(range(1, num_storage + 1))}\n",
    "        }\n",
    "        \n",
    "        reda_data = {}\n",
    "        re_scenarios = {}\n",
    "        \n",
    "        fo_params = {\n",
    "            # Manual values\n",
    "            'D1': {None: 5},\n",
    "            'D2': {None: 550.0},\n",
    "            'PEN': {None: 2000},\n",
    "            'PENDN': {None: 0},\n",
    "            'smallM': {None: 0.01},\n",
    "            # check probabilities\n",
    "            'probTU': {r: 0.2 + 0.1 * (r-1) for r in range(1, num_tiers + 1)},\n",
    "            'probTD': {r: 0.2 + 0.1 * (r-1) for r in range(1, num_tiers + 1)}\n",
    "        }\n",
    "        \n",
    "        pyomo_data = {}\n",
    "        pyomo_data.update(sets)\n",
    "        pyomo_data.update(gen_data_dict)\n",
    "        pyomo_data.update(storage_data_dict)\n",
    "        pyomo_data.update({\"DEMAND\": demand_data_dict})\n",
    "        pyomo_data.update(fo_params)\n",
    "        \n",
    "        # TODO - CALCULATE REDA, RE\n",
    "        pyomo_data['REDA'] = reda_data\n",
    "        pyomo_data['RE'] = re_scenarios\n",
    "        pyomo_data = {None: pyomo_data}\n",
    "\n",
    "        # TODO: UPDATE REQUIRED PARAMETERS\n",
    "        required_params = [\n",
    "            'CAP', 'VC', 'VCUP', 'VCDN', 'RR',\n",
    "            'E_MAX', 'P_MAX', 'ETA_CH', 'ETA_DCH', 'E0', 'E_FINAL', 'STORAGE_COST',\n",
    "            'D1', 'D2', 'PEN', 'PENDN', 'smallM', 'probTU', 'probTD',\n",
    "            'DEMAND', 'REDA', 'RE'\n",
    "        ]\n",
    "        \n",
    "        missing_params = [param for param in required_params if param not in pyomo_data[None]]\n",
    "        if missing_params:\n",
    "            print(f\"Warning: Missing parameters: {missing_params}\")\n",
    "        \n",
    "        return pyomo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator and Storage data loaded successfully. 5 generators and 5 storages found.\n",
      "Demand data loaded successfully. 8784 periods found.\n",
      "{\n",
      "    \"B\": {\n",
      "        \"null\": [\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "            4,\n",
      "            5\n",
      "        ]\n",
      "    },\n",
      "    \"CAP\": {\n",
      "        \"1\": 20.0,\n",
      "        \"2\": 20.0,\n",
      "        \"3\": 76.0,\n",
      "        \"4\": 76.0,\n",
      "        \"5\": 20.0\n",
      "    },\n",
      "    \"D1\": {\n",
      "        \"null\": 5\n",
      "    },\n",
      "    \"D2\": {\n",
      "        \"null\": 550.0\n",
      "    },\n",
      "    \"DEMAND\": {\n",
      "        \"1\": 985.0197922,\n",
      "        \"2\": 985.7248887,\n",
      "        \"3\": 1001.58956,\n",
      "        \"4\": 1036.139287,\n",
      "        \"5\": 1139.788471,\n",
      "        \"6\": 1286.801089,\n",
      "        \"7\": 1347.086838,\n",
      "        \"8\": 1305.486145,\n",
      "        \"9\": 1232.508659,\n",
      "        \"10\": 1184.20955,\n",
      "        \"11\": 1153.185304,\n",
      "        \"12\": 1129.212024,\n",
      "        \"13\": 1107.706581,\n",
      "        \"14\": 1093.957199,\n",
      "        \"15\": 1087.611331,\n",
      "        \"16\": 1091.489362,\n",
      "        \"17\": 1170.460168,\n",
      "        \"18\": 1280.102672,\n",
      "        \"19\": 1266.000742,\n",
      "        \"20\": 1245.200396,\n",
      "        \"21\": 1204.657348,\n",
      "        \"22\": 1117.577932,\n",
      "        \"23\": 1031.203612,\n",
      "        \"24\": 991.0131123\n",
      "    },\n",
      "    \"E0\": {\n",
      "        \"1\": 0.0,\n",
      "        \"2\": 0.0,\n",
      "        \"3\": 0.0,\n",
      "        \"4\": 0.0,\n",
      "        \"5\": 0.0\n",
      "    },\n",
      "    \"ETA_CH\": {\n",
      "        \"1\": 0.9,\n",
      "        \"2\": 0.9,\n",
      "        \"3\": 0.9,\n",
      "        \"4\": 0.9,\n",
      "        \"5\": 0.9\n",
      "    },\n",
      "    \"ETA_DCH\": {\n",
      "        \"1\": 0.9,\n",
      "        \"2\": 0.9,\n",
      "        \"3\": 0.9,\n",
      "        \"4\": 0.9,\n",
      "        \"5\": 0.9\n",
      "    },\n",
      "    \"E_FINAL\": {\n",
      "        \"1\": 0.0,\n",
      "        \"2\": 0.0,\n",
      "        \"3\": 0.0,\n",
      "        \"4\": 0.0,\n",
      "        \"5\": 0.0\n",
      "    },\n",
      "    \"E_MAX\": {\n",
      "        \"1\": 1200.0,\n",
      "        \"2\": 150.0,\n",
      "        \"3\": 150.0,\n",
      "        \"4\": 1000.0,\n",
      "        \"5\": 1000.0\n",
      "    },\n",
      "    \"G\": {\n",
      "        \"null\": [\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "            4,\n",
      "            5\n",
      "        ]\n",
      "    },\n",
      "    \"PEN\": {\n",
      "        \"null\": 2000\n",
      "    },\n",
      "    \"PENDN\": {\n",
      "        \"null\": 0\n",
      "    },\n",
      "    \"P_MAX\": {\n",
      "        \"1\": 200.0,\n",
      "        \"2\": 50.0,\n",
      "        \"3\": 50.0,\n",
      "        \"4\": 50.0,\n",
      "        \"5\": 50.0\n",
      "    },\n",
      "    \"R\": {\n",
      "        \"null\": [\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "            4\n",
      "        ]\n",
      "    },\n",
      "    \"RE\": {},\n",
      "    \"REDA\": {},\n",
      "    \"RR\": {\n",
      "        \"1\": 3.0,\n",
      "        \"2\": 3.0,\n",
      "        \"3\": 2.0,\n",
      "        \"4\": 2.0,\n",
      "        \"5\": 3.0\n",
      "    },\n",
      "    \"S\": {\n",
      "        \"null\": [\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "            4,\n",
      "            5\n",
      "        ]\n",
      "    },\n",
      "    \"STORAGE_COST\": {\n",
      "        \"1\": 0.9,\n",
      "        \"2\": 0.9,\n",
      "        \"3\": 0.9,\n",
      "        \"4\": 0.9,\n",
      "        \"5\": 0.9\n",
      "    },\n",
      "    \"VC\": {\n",
      "        \"1\": 20,\n",
      "        \"2\": 20,\n",
      "        \"3\": 20,\n",
      "        \"4\": 20,\n",
      "        \"5\": 20\n",
      "    },\n",
      "    \"VCDN\": {\n",
      "        \"1\": 20,\n",
      "        \"2\": 20,\n",
      "        \"3\": 20,\n",
      "        \"4\": 20,\n",
      "        \"5\": 20\n",
      "    },\n",
      "    \"VCUP\": {\n",
      "        \"1\": 20,\n",
      "        \"2\": 20,\n",
      "        \"3\": 20,\n",
      "        \"4\": 20,\n",
      "        \"5\": 20\n",
      "    },\n",
      "    \"probTD\": {\n",
      "        \"1\": 0.2,\n",
      "        \"2\": 0.30000000000000004,\n",
      "        \"3\": 0.4,\n",
      "        \"4\": 0.5\n",
      "    },\n",
      "    \"probTU\": {\n",
      "        \"1\": 0.2,\n",
      "        \"2\": 0.30000000000000004,\n",
      "        \"3\": 0.4,\n",
      "        \"4\": 0.5\n",
      "    },\n",
      "    \"smallM\": {\n",
      "        \"null\": 0.01\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot load a SolverResults object with bad status: error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m solver_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Program Files/IBM/ILOG/CPLEX_Studio_Community2212/cplex/bin/x64_win64/cplex\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     30\u001b[0m opt \u001b[38;5;241m=\u001b[39m pyo\u001b[38;5;241m.\u001b[39mSolverFactory(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcplex\u001b[39m\u001b[38;5;124m'\u001b[39m,executable\u001b[38;5;241m=\u001b[39msolver_path)\n\u001b[1;32m---> 32\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mda_instance\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\opt\\base\\solvers.py:662\u001b[0m, in \u001b[0;36mOptSolver.solve\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_solutions:\n\u001b[1;32m--> 662\u001b[0m         \u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolutions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m            \u001b[49m\u001b[43mselect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdefault_variable_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_variable_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    667\u001b[0m         result\u001b[38;5;241m.\u001b[39m_smap_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    668\u001b[0m         result\u001b[38;5;241m.\u001b[39msolution\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[1;32mc:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\PyomoModel.py:231\u001b[0m, in \u001b[0;36mModelSolutions.load_from\u001b[1;34m(self, results, allow_consistent_values_for_fixed_vars, comparison_tolerance_for_fixed_vars, ignore_invalid_labels, id, delete_symbol_map, clear, default_variable_value, select, ignore_fixed_vars)\u001b[0m\n\u001b[0;32m    226\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    227\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading a SolverResults object with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maborted\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m status, but containing a solution\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m         )\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 231\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    232\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load a SolverResults object \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith bad status: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(results\u001b[38;5;241m.\u001b[39msolver\u001b[38;5;241m.\u001b[39mstatus)\n\u001b[0;32m    234\u001b[0m         )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clear:\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;66;03m# Clear the solutions, but not the symbol map\u001b[39;00m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear(clear_symbol_maps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot load a SolverResults object with bad status: error"
     ]
    }
   ],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super().default(obj)\n",
    "\n",
    "gen_csv_path = 'system_data/gen.csv'\n",
    "storage_csv_path = 'system_data/storage.csv'\n",
    "demand_csv_path = 'system_data/DAY_AHEAD_regional_load.csv'\n",
    "\n",
    "system_data = SystemDataProcessor(gen_csv_path, storage_csv_path, demand_csv_path)\n",
    "pyomo_system_data = system_data.prepare_pyomo_data()\n",
    "print(json.dumps(pyomo_system_data[None], cls=NumpyEncoder, indent=4, sort_keys=True))\n",
    "\n",
    "dafo_model = DAFOModel(\n",
    "    num_periods=24,\n",
    "    num_scenarios=1,\n",
    "    num_generators=5,\n",
    "    num_tiers=4,\n",
    "    num_storage=5\n",
    ")\n",
    "\n",
    "da_instance = dafo_model.create_instance(pyomo_system_data)\n",
    "solver_path = 'C:/Program Files/IBM/ILOG/CPLEX_Studio_Community2212/cplex/bin/x64_win64/cplex'\n",
    "opt = pyo.SolverFactory('cplex',executable=solver_path)\n",
    "\n",
    "opt.solve(da_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSolver:\n",
    "    def __init__(self, solver_path=None):\n",
    "        \"\"\"Initialize the model solver with optional solver path\"\"\"\n",
    "        self.solver_path = solver_path\n",
    "        self.opt = self._setup_solver()\n",
    "        \n",
    "    def _setup_solver(self):\n",
    "        \"\"\"Setup the solver using CPLEX\"\"\"\n",
    "        try:\n",
    "            if self.solver_path:\n",
    "                opt = pyo.SolverFactory('cplex', executable=self.solver_path)    \n",
    "            else:\n",
    "                opt = pyo.SolverFactory('cplex')\n",
    "                    \n",
    "            if not opt.available():\n",
    "                print(\"ERROR: CPLEX is unavailable. Please check installation.\")\n",
    "                return None\n",
    "               \n",
    "            return opt\n",
    "        except Exception as e:\n",
    "            print(f\"Error setting up solver: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def solve_da_model(self, da_data):\n",
    "        \"\"\"Solve the DA model with Flexibility Options\"\"\"\n",
    "        try:\n",
    "            # Create DAFOModel instance with explicit dimensions\n",
    "            num_periods = 24  # Default\n",
    "            num_scenarios = 5  # Default\n",
    "            num_generators = 5  # Default\n",
    "            num_tiers = 4  # Default\n",
    "            num_storage = 3  # Default\n",
    "            \n",
    "            # Try to determine dimensions from the data\n",
    "            if 'T' in da_data and None in da_data['T']:\n",
    "                num_periods = len(da_data['T'][None])\n",
    "            if 'S' in da_data and None in da_data['S']:\n",
    "                num_scenarios = len(da_data['S'][None])\n",
    "            if 'G' in da_data and None in da_data['G']:\n",
    "                num_generators = len(da_data['G'][None])\n",
    "            if 'R' in da_data and None in da_data['R']:\n",
    "                num_tiers = len(da_data['R'][None])\n",
    "            if 'B' in da_data and None in da_data['B']:\n",
    "                num_storage = len(da_data['B'][None])\n",
    "            \n",
    "            # Validate that all required parameters exist\n",
    "            required_params = ['DEMAND', 'REDA', 'RE', 'VC', 'VCUP', 'VCDN', 'CAP', 'RR',\n",
    "                            'D1', 'D2', 'PEN', 'PENDN', 'smallM', 'probTU', 'probTD',\n",
    "                            'E_MAX', 'P_MAX', 'ETA_CH', 'ETA_DCH', 'E0', 'E_FINAL', 'STORAGE_COST']\n",
    "            \n",
    "            # Print validation info\n",
    "            print(f\"Validating model parameters:\")\n",
    "            print(f\"num_periods: {num_periods}\")\n",
    "            print(f\"num_scenarios: {num_scenarios}\")\n",
    "            print(f\"num_generators: {num_generators}\")\n",
    "            print(f\"num_tiers: {num_tiers}\")\n",
    "            print(f\"num_storage: {num_storage}\")\n",
    "            \n",
    "            missing_params = [p for p in required_params if p not in da_data]\n",
    "            if missing_params:\n",
    "                print(f\"WARNING: Missing parameters: {missing_params}\")\n",
    "                # Add default values for missing parameters\n",
    "                for p in missing_params:\n",
    "                    if p == 'DEMAND':\n",
    "                        da_data[p] = {t: 100.0 for t in range(1, num_periods + 1)}\n",
    "                    elif p == 'REDA':\n",
    "                        da_data[p] = {t: 0.0 for t in range(1, num_periods + 1)}\n",
    "                    elif p == 'RE':\n",
    "                        da_data[p] = {(s, t): 0.0 for s in range(1, num_scenarios + 1) \n",
    "                                    for t in range(1, num_periods + 1)}\n",
    "                    elif p in ['D1', 'D2', 'PEN', 'PENDN', 'smallM']:\n",
    "                        da_data[p] = {None: 10.0 if p == 'D1' else 0.1 if p == 'D2' else \n",
    "                                    500.0 if p == 'PEN' else 200.0 if p == 'PENDN' else 0.0001}\n",
    "                    elif p in ['probTU', 'probTD']:\n",
    "                        da_data[p] = {r: 0.2 + 0.1 * (r-1) for r in range(1, num_tiers + 1)}\n",
    "                    # Add other parameter defaults as needed\n",
    "            \n",
    "            # Validate indices in DEMAND parameter\n",
    "            if 'DEMAND' in da_data:\n",
    "                missing_times = [t for t in range(1, num_periods + 1) if t not in da_data['DEMAND']]\n",
    "                if missing_times:\n",
    "                    print(f\"WARNING: Missing time periods in DEMAND: {missing_times}\")\n",
    "                    for t in missing_times:\n",
    "                        da_data['DEMAND'][t] = 100.0  # Default value\n",
    "            \n",
    "            dafo_model = DAFOModel(\n",
    "                num_periods=num_periods,\n",
    "                num_scenarios=num_scenarios,\n",
    "                num_generators=num_generators,\n",
    "                num_tiers=num_tiers,\n",
    "                num_storage=num_storage\n",
    "            )\n",
    "            \n",
    "            # Debug: print a subset of the DEMAND parameter\n",
    "            print(f\"Sample of DEMAND parameter: {dict(list(da_data['DEMAND'].items())[:5])}\")\n",
    "            \n",
    "            # Create model instance\n",
    "            instance = dafo_model.create_instance(da_data)\n",
    "            print(\"DA model instance created successfully\")\n",
    "            \n",
    "            # Solve model\n",
    "            result = self.solve_with_handling(instance)\n",
    "            \n",
    "            if result:\n",
    "                # Store key outputs\n",
    "                outputs = self._extract_da_outputs(instance)\n",
    "                return instance, outputs\n",
    "            else:\n",
    "                print(\"Failed to solve DA model\")\n",
    "                return None, None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in DA model: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None, None\n",
    "    \n",
    "    def solve_rt_model(self, rt_data, da_outputs=None):\n",
    "        \"\"\"Solve the RT model for each scenario\"\"\"\n",
    "        try:\n",
    "            # Create RTSimModel instance with explicit dimensions\n",
    "            num_periods = len(rt_data.get('T', {}).get(None, [24]))\n",
    "            num_scenarios = len(rt_data.get('S', {}).get(None, [5]))\n",
    "            num_generators = len(rt_data.get('G', {}).get(None, [5]))\n",
    "            num_storage = len(rt_data.get('B', {}).get(None, [3]))\n",
    "            \n",
    "            rtsim_model = RTSimModel(\n",
    "                num_periods=num_periods,\n",
    "                num_scenarios=num_scenarios,\n",
    "                num_generators=num_generators,\n",
    "                num_storage=num_storage\n",
    "            )\n",
    "            \n",
    "            # Add DA outputs to RT data if provided\n",
    "            if da_outputs:\n",
    "                for key, value in da_outputs.items():\n",
    "                    if key not in rt_data:\n",
    "                        rt_data[key] = value\n",
    "            \n",
    "            # Create model instance\n",
    "            instance = rtsim_model.create_instance(rt_data)\n",
    "            print(\"RT model instance created successfully\")\n",
    "            \n",
    "            # Solve model\n",
    "            result = self.solve_with_handling(instance)\n",
    "            \n",
    "            if result:\n",
    "                # Store key outputs\n",
    "                outputs = self._extract_rt_outputs(instance)\n",
    "                return instance, outputs\n",
    "            else:\n",
    "                print(\"Failed to solve RT model\")\n",
    "                return None, None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in RT model: {str(e)}\")\n",
    "            return None, None\n",
    "    \n",
    "    def solve_with_handling(self, model):\n",
    "        \"\"\"Solve a Pyomo model with error handling\"\"\"\n",
    "        try:\n",
    "            result = self.opt.solve(model, tee=True)\n",
    "            \n",
    "            if (result.solver.status == pyo.SolverStatus.ok and \n",
    "                result.solver.termination_condition == pyo.TerminationCondition.optimal):\n",
    "                print(\"Model solved successfully\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"Solver status: {result.solver.status}\")\n",
    "                print(f\"Termination condition: {result.solver.termination_condition}\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error solving model: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def _extract_da_outputs(self, instance):\n",
    "        \"\"\"Extract key outputs from DA model instance\"\"\"\n",
    "        outputs = {}\n",
    "        \n",
    "        try:\n",
    "            # Extract energy schedules\n",
    "            if hasattr(instance, 'xDA'):\n",
    "                outputs['xDA'] = {(g, t): instance.xDA[g, t].value for g in instance.G for t in instance.T}\n",
    "            \n",
    "            # Extract renewable schedule\n",
    "            if hasattr(instance, 'rgDA'):\n",
    "                outputs['REDA'] = {t: instance.rgDA[t].value for t in instance.T}\n",
    "            \n",
    "            # Extract storage schedules if storage exists\n",
    "            if hasattr(instance, 'e') and hasattr(instance, 'p_ch') and hasattr(instance, 'p_dch'):\n",
    "                outputs['e_DA'] = {(b, t): instance.e[b, t].value for b in instance.B for t in instance.T}\n",
    "                outputs['p_ch_DA'] = {(b, t): instance.p_ch[b, t].value for b in instance.B for t in instance.T}\n",
    "                outputs['p_dch_DA'] = {(b, t): instance.p_dch[b, t].value for b in instance.B for t in instance.T}\n",
    "            \n",
    "            # Extract FO schedules for all suppliers (generators + storage)\n",
    "            if hasattr(instance, 'hsu') and hasattr(instance, 'hsd'):\n",
    "                outputs['hsu'] = {(r, g, t): instance.hsu[r, g, t].value for r in instance.R for g in instance.G for t in instance.T}\n",
    "                outputs['hsd'] = {(r, g, t): instance.hsd[r, g, t].value for r in instance.R for g in instance.G for t in instance.T}\n",
    "            \n",
    "            if hasattr(instance, 'bsu') and hasattr(instance, 'bsd'):\n",
    "                outputs['bsu'] = {(r, b, t): instance.bsu[r, b, t].value for r in instance.R for b in instance.B for t in instance.T}\n",
    "                outputs['bsd'] = {(r, b, t): instance.bsd[r, b, t].value for r in instance.R for b in instance.B for t in instance.T}\n",
    "            \n",
    "            # Extract FO demand\n",
    "            if hasattr(instance, 'hdu') and hasattr(instance, 'hdd'):\n",
    "                outputs['hdu'] = {(r, t): instance.hdu[r, t].value for r in instance.R for t in instance.T}\n",
    "                outputs['hdd'] = {(r, t): instance.hdd[r, t].value for r in instance.R for t in instance.T}\n",
    "            \n",
    "            # Extract prices\n",
    "            if hasattr(instance, 'dual'):\n",
    "                if hasattr(instance, 'Con3'):\n",
    "                    outputs['DA_price'] = {t: instance.dual[instance.Con3[t]] for t in instance.T}\n",
    "                if hasattr(instance, 'Con4UP'):\n",
    "                    outputs['FO_up_price'] = {(r, t): instance.dual[instance.Con4UP[r, t]] for r in instance.R for t in instance.T}\n",
    "                if hasattr(instance, 'Con4DN'):\n",
    "                    outputs['FO_down_price'] = {(r, t): instance.dual[instance.Con4DN[r, t]] for r in instance.R for t in instance.T}\n",
    "            \n",
    "            # Extract total costs\n",
    "            if hasattr(instance, 'OBJ'):\n",
    "                outputs['total_cost'] = pyo.value(instance.OBJ)\n",
    "            \n",
    "            # Extract demand slack\n",
    "            if hasattr(instance, 'd'):\n",
    "                outputs['DAdr'] = {t: instance.d[t].value for t in instance.T}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting DA outputs: {str(e)}\")\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def _extract_rt_outputs(self, instance):\n",
    "        \"\"\"Extract key outputs from RT model instance\"\"\"\n",
    "        outputs = {}\n",
    "        \n",
    "        try:\n",
    "            # Extract RT energy adjustments if generators exist\n",
    "            if hasattr(instance, 'xup') and hasattr(instance, 'xdn'):\n",
    "                outputs['xup'] = {(s, g, t): instance.xup[s, g, t].value for s in instance.S for g in instance.G for t in instance.T}\n",
    "                outputs['xdn'] = {(s, g, t): instance.xdn[s, g, t].value for s in instance.S for g in instance.G for t in instance.T}\n",
    "            \n",
    "            # Extract storage adjustments if storage exists\n",
    "            if hasattr(instance, 'e') and hasattr(instance, 'p_ch') and hasattr(instance, 'p_dch'):\n",
    "                outputs['e_RT'] = {(s, b, t): instance.e[s, b, t].value for s in instance.S for b in instance.B for t in instance.T}\n",
    "                outputs['p_ch_RT'] = {(s, b, t): instance.p_ch[s, b, t].value for s in instance.S for b in instance.B for t in instance.T}\n",
    "                outputs['p_dch_RT'] = {(s, b, t): instance.p_dch[s, b, t].value for s in instance.S for b in instance.B for t in instance.T}\n",
    "            \n",
    "            if hasattr(instance, 'b_up') and hasattr(instance, 'b_dn'):\n",
    "                outputs['b_up'] = {(s, b, t): instance.b_up[s, b, t].value for s in instance.S for b in instance.B for t in instance.T}\n",
    "                outputs['b_dn'] = {(s, b, t): instance.b_dn[s, b, t].value for s in instance.S for b in instance.B for t in instance.T}\n",
    "            \n",
    "            # Extract RE adjustments\n",
    "            if hasattr(instance, 'rgup') and hasattr(instance, 'rgdn'):\n",
    "                outputs['rgup'] = {(s, t): instance.rgup[s, t].value for s in instance.S for t in instance.T}\n",
    "                outputs['rgdn'] = {(s, t): instance.rgdn[s, t].value for s in instance.S for t in instance.T}\n",
    "            \n",
    "            # Extract shortage/surplus\n",
    "            if hasattr(instance, 'sdup') and hasattr(instance, 'sddn'):\n",
    "                outputs['sdup'] = {(s, t): instance.sdup[s, t].value for s in instance.S for t in instance.T}\n",
    "                outputs['sddn'] = {(s, t): instance.sddn[s, t].value for s in instance.S for t in instance.T}\n",
    "            \n",
    "            # Extract RT prices\n",
    "            if hasattr(instance, 'dual') and hasattr(instance, 'Con3'):\n",
    "                outputs['RT_price'] = {(s, t): instance.dual[instance.Con3[s, t]] for s in instance.S for t in instance.T}\n",
    "            \n",
    "            # Extract total costs per scenario\n",
    "            if hasattr(instance, 'prob') and hasattr(instance, 'VCUP') and hasattr(instance, 'VCDN'):\n",
    "                outputs['scenario_costs'] = {}\n",
    "                for s in instance.S:\n",
    "                    scenario_cost = 0\n",
    "                    if hasattr(instance, 'xup') and hasattr(instance, 'xdn'):\n",
    "                        scenario_cost += sum(\n",
    "                            instance.prob[s] * (\n",
    "                                sum(instance.VCUP[g] * instance.xup[s, g, t].value - \n",
    "                                    instance.VCDN[g] * instance.xdn[s, g, t].value \n",
    "                                    for g in instance.G for t in instance.T)\n",
    "                            ))\n",
    "                    outputs['scenario_costs'][s] = scenario_cost\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting RT outputs: {str(e)}\")\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Flexibility Options with Storage Analysis...\n",
      "Data processor initialized.\n",
      "DA model parameters:\n",
      "VC: {1: 20.0, 2: 30.0, 3: 40.0, 4: 50.0, 5: 60.0}\n",
      "VCUP: {1: 30.0, 2: 45.0, 3: 60.0, 4: 75.0, 5: 90.0}\n",
      "VCDN: {1: 10.0, 2: 15.0, 3: 20.0, 4: 25.0, 5: 30.0}\n",
      "CAP: {1: 100.0, 2: 20.0, 3: 20.0, 4: 20.0, 5: 20.0}\n",
      "RR: {1: 20.0, 2: 10.0, 3: 10.0, 4: 10.0, 5: 10.0}\n",
      "RT model parameters:\n",
      "VC: {1: 20.0, 2: 30.0, 3: 40.0, 4: 50.0, 5: 60.0}\n",
      "VCUP: {1: 30.0, 2: 45.0, 3: 60.0, 4: 75.0, 5: 90.0}\n",
      "VCDN: {1: 10.0, 2: 15.0, 3: 20.0, 4: 25.0, 5: 30.0}\n",
      "CAP: {1: 100.0, 2: 20.0, 3: 20.0, 4: 20.0, 5: 20.0}\n",
      "RR: {1: 20.0, 2: 10.0, 3: 10.0, 4: 10.0, 5: 10.0}\n",
      "Data preparation completed.\n",
      "Model solver initialized.\n",
      "\n",
      "Solving DA model with Flexibility Options...\n",
      "Validating model parameters:\n",
      "num_periods: 24\n",
      "num_scenarios: 5\n",
      "num_generators: 5\n",
      "num_tiers: 4\n",
      "num_storage: 3\n",
      "Sample of DEMAND parameter: {1: 120.0, 2: 125.0, 3: 135.0, 4: 150.0, 5: 160.0}\n",
      "ERROR: Rule failed when generating expression for Constraint Con3 with index\n",
      "1: ValueError: Error retrieving immutable Param value (DEMAND[1]):\n",
      "            The Param value is undefined and no default value is specified.\n",
      "ERROR: Constructing component 'Con3' from data=None failed:\n",
      "        ValueError: Error retrieving immutable Param value (DEMAND[1]):\n",
      "    \tThe Param value is undefined and no default value is specified.\n",
      "Error in DA model: Error retrieving immutable Param value (DEMAND[1]):\n",
      "\tThe Param value is undefined and no default value is specified.\n",
      "ERROR: DA model solution failed. Exiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hanbo\\AppData\\Local\\Temp\\ipykernel_7428\\853726351.py\", line 98, in solve_da_model\n",
      "    instance = dafo_model.create_instance(da_data)\n",
      "  File \"C:\\Users\\hanbo\\AppData\\Local\\Temp\\ipykernel_7428\\3517868776.py\", line 261, in create_instance\n",
      "    return self.model.create_instance(data)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\PyomoModel.py\", line 734, in create_instance\n",
      "    instance.load(data, namespaces=_namespaces, profile_memory=profile_memory)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\PyomoModel.py\", line 771, in load\n",
      "    self._load_model_data(dp, namespaces, profile_memory=profile_memory)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\PyomoModel.py\", line 823, in _load_model_data\n",
      "    self._initialize_component(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        modeldata, namespaces, component_name, profile_memory\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\PyomoModel.py\", line 871, in _initialize_component\n",
      "    declaration.construct(data)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\constraint.py\", line 720, in construct\n",
      "    self._setitem_when_not_present(index, rule(block, index))\n",
      "                                          ~~~~^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\initializer.py\", line 349, in __call__\n",
      "    return self._fcn(parent, idx)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hanbo\\AppData\\Local\\Temp\\ipykernel_7428\\3517868776.py\", line 166, in DA_energy_balance\n",
      "    model.d[t] == model.DEMAND[t])\n",
      "                  ~~~~~~~~~~~~^^^\n",
      "  File \"c:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\param.py\", line 1014, in __getitem__\n",
      "    return super().__getitem__(args)\n",
      "           ~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\indexed_component.py\", line 662, in __getitem__\n",
      "    return self._getitem_when_not_present(index)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\param.py\", line 624, in _getitem_when_not_present\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Error retrieving immutable Param value (DEMAND[1]):\n",
      "\tThe Param value is undefined and no default value is specified.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    input_file = 'sample.csv'\n",
    "    output_dir = 'Flexibility_Options_Results'\n",
    "    solver_path = 'C:/Program Files/IBM/ILOG/CPLEX_Studio_Community2212/cplex/bin/x64_win64/cplex'\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        print(\"Starting Flexibility Options with Storage Analysis...\")\n",
    "        \n",
    "        # Initialize data processor with explicit dimensions\n",
    "        processor = DataProcessor(input_file)\n",
    "        print(\"Data processor initialized.\")\n",
    "        \n",
    "        # Prepare DA and RT data\n",
    "        da_data = processor.prepare_da_data()\n",
    "        rt_data = processor.prepare_rt_data()\n",
    "        print(\"Data preparation completed.\")\n",
    "        \n",
    "        # Initialize model solver\n",
    "        solver = ModelSolver(solver_path)\n",
    "        if solver.opt is None:\n",
    "            print(\"ERROR: Solver initialization failed. Exiting...\")\n",
    "            return\n",
    "        print(\"Model solver initialized.\")\n",
    "        \n",
    "        # Solve DA model\n",
    "        print(\"\\nSolving DA model with Flexibility Options...\")\n",
    "        da_instance, da_outputs = solver.solve_da_model(da_data)\n",
    "        \n",
    "        if da_instance is None or da_outputs is None:\n",
    "            print(\"ERROR: DA model solution failed. Exiting...\")\n",
    "            return\n",
    "        print(\"DA model solved successfully.\")\n",
    "        \n",
    "        # Export DA model solution to CSV\n",
    "        export_solution_to_csv(da_outputs, os.path.join(output_dir, 'da_solution.csv'))\n",
    "        \n",
    "        # Solve RT model\n",
    "        print(\"\\nSolving RT model for each scenario...\")\n",
    "        # Update RT data with DA outputs\n",
    "        for key, value in da_outputs.items():\n",
    "            if key in ['xDA', 'REDA', 'e_DA', 'p_ch_DA', 'p_dch_DA', 'DAdr']:\n",
    "                rt_data[key] = value\n",
    "        \n",
    "        rt_instance, rt_outputs = solver.solve_rt_model(rt_data)\n",
    "        \n",
    "        if rt_instance is None or rt_outputs is None:\n",
    "            print(\"ERROR: RT model solution failed. Exiting...\")\n",
    "            return\n",
    "        print(\"RT model solved successfully.\")\n",
    "        \n",
    "        # Export RT model solution to CSV\n",
    "        export_solution_to_csv(rt_outputs, os.path.join(output_dir, 'rt_solution.csv'))\n",
    "        \n",
    "        # Analyze results\n",
    "        print(\"\\nAnalyzing results...\")\n",
    "        analyzer = ResultsAnalyzer(da_outputs, rt_outputs)\n",
    "        analysis_results = analyzer.run_full_analysis()\n",
    "        print(\"Analysis completed and visualizations generated.\")\n",
    "        \n",
    "        # Export key model outputs for further analysis\n",
    "        export_model_outputs(da_instance, rt_instance, os.path.join(output_dir, 'model_outputs.xlsx'))\n",
    "        print(f\"Model outputs exported to {os.path.join(output_dir, 'model_outputs.xlsx')}\")\n",
    "        \n",
    "        print(\"\\nSummary:\")\n",
    "        print(f\"- Total DA cost: ${da_outputs.get('total_cost', 0):.2f}\")\n",
    "        \n",
    "        if analysis_results and 'fo_summary' in analysis_results and 'storage_fo_contribution' in analysis_results['fo_summary']:\n",
    "            storage_contrib = analysis_results['fo_summary']['storage_fo_contribution']\n",
    "            avg_storage_contrib = np.mean([v for k, v in storage_contrib.items()]) * 100\n",
    "            print(f\"- Average storage contribution to FOs: {avg_storage_contrib:.2f}%\")\n",
    "        \n",
    "        print(f\"- Full results available in: {output_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {str(e)}\")\n",
    "\n",
    "def export_solution_to_csv(outputs, filename):\n",
    "    \"\"\"Export model solution to CSV file\"\"\"\n",
    "    try:\n",
    "        # Convert nested dictionaries to DataFrame\n",
    "        data = []\n",
    "        for key, values in outputs.items():\n",
    "            if isinstance(values, dict):\n",
    "                for idx, val in values.items():\n",
    "                    if isinstance(idx, tuple):\n",
    "                        # Handle multi-index keys\n",
    "                        row = list(idx)\n",
    "                        row_dict = {'parameter': key, 'value': val}\n",
    "                        for i, dim in enumerate(idx):\n",
    "                            row_dict[f'dim{i+1}'] = dim\n",
    "                        data.append(row_dict)\n",
    "                    else:\n",
    "                        # Handle single-index keys\n",
    "                        data.append({'parameter': key, 'dim1': idx, 'value': val})\n",
    "            else:\n",
    "                # Handle scalar values\n",
    "                data.append({'parameter': key, 'value': values})\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Solution exported to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting solution: {str(e)}\")\n",
    "\n",
    "def export_model_outputs(da_instance, rt_instance, filename):\n",
    "    \"\"\"Export raw model outputs for further analysis\"\"\"\n",
    "    try:\n",
    "        with pd.ExcelWriter(filename) as writer:\n",
    "            # Export dual variables from DA model\n",
    "            da_duals = {}\n",
    "            for c in da_instance.component_objects(pyo.Constraint, active=True):\n",
    "                for idx in c:\n",
    "                    if idx in da_instance.dual:\n",
    "                        da_duals[f\"{c.name}_{idx}\"] = da_instance.dual[idx]\n",
    "            \n",
    "            pd.Series(da_duals).to_frame('Value').to_excel(writer, 'DA_Duals')\n",
    "            \n",
    "            # Export storage-related variables from DA model\n",
    "            storage_vars = {}\n",
    "            for v_name in ['e', 'p_ch', 'p_dch', 'bsu', 'bsd']:\n",
    "                if hasattr(da_instance, v_name):\n",
    "                    v = getattr(da_instance, v_name)\n",
    "                    for idx in v:\n",
    "                        storage_vars[f\"{v_name}_{idx}\"] = v[idx].value\n",
    "            \n",
    "            pd.Series(storage_vars).to_frame('Value').to_excel(writer, 'DA_Storage_Variables')\n",
    "            \n",
    "            # Export RT energy prices\n",
    "            if hasattr(rt_instance, 'dual'):\n",
    "                rt_prices = {}\n",
    "                for s in rt_instance.S:\n",
    "                    for t in rt_instance.T:\n",
    "                        if hasattr(rt_instance, 'Con3') and (s, t) in rt_instance.Con3:\n",
    "                            if (s, t) in rt_instance.dual:\n",
    "                                rt_prices[f\"RT_price_s{s}_t{t}\"] = rt_instance.dual[(s, t)]\n",
    "                \n",
    "                pd.Series(rt_prices).to_frame('Value').to_excel(writer, 'RT_Prices')\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting model outputs: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating visualizations: [Errno 2] No such file or directory: 'Test_output_files/Results_SectionV\\\\Summary_Results_2025_02_27.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_summary_results(summary_file):\n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        system_cost = pd.read_excel(summary_file, sheet_name='System_Cost', index_col=0)\n",
    "        price_conv = pd.read_excel(summary_file, sheet_name='Price_Convergence', index_col=0)\n",
    "        premium_up = pd.read_excel(summary_file, sheet_name='Premium_Up', index_col=0)\n",
    "        premium_down = pd.read_excel(summary_file, sheet_name='Premium_Down', index_col=0)\n",
    "        demand_cost = pd.read_excel(summary_file, sheet_name='Demand_Cost', index_col=0)\n",
    "        curtail_cost = pd.read_excel(summary_file, sheet_name='Curtailment_Cost', index_col=0)\n",
    "        \n",
    "        # Check if dataframes contain numeric data\n",
    "        if (system_cost.empty or price_conv.empty or premium_up.empty or \n",
    "            premium_down.empty or demand_cost.empty or curtail_cost.empty):\n",
    "            print(\"Error: One or more sheets contain no data\")\n",
    "            return\n",
    "            \n",
    "        # Convert data to numeric, replacing non-numeric values with NaN\n",
    "        system_cost = system_cost.apply(pd.to_numeric, errors='coerce')\n",
    "        price_conv = price_conv.apply(pd.to_numeric, errors='coerce')\n",
    "        premium_up = premium_up.apply(pd.to_numeric, errors='coerce')\n",
    "        premium_down = premium_down.apply(pd.to_numeric, errors='coerce')\n",
    "        demand_cost = demand_cost.apply(pd.to_numeric, errors='coerce')\n",
    "        curtail_cost = curtail_cost.apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(15, 15))\n",
    "        fig.suptitle('Summary Results Visualization')\n",
    "        \n",
    "        # Plot system cost\n",
    "        if not system_cost.empty and system_cost.notna().any().any():\n",
    "            system_cost.plot(kind='bar', ax=axes[0,0], title='System Cost')\n",
    "            axes[0,0].set_ylabel('Cost')\n",
    "            axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            axes[0,0].set_title('System Cost - No numeric data available')\n",
    "        \n",
    "        # Plot price convergence\n",
    "        if not price_conv.empty and price_conv.notna().any().any():\n",
    "            price_conv.plot(kind='bar', ax=axes[0,1], title='Price Convergence')\n",
    "            axes[0,1].set_ylabel('Price')\n",
    "            axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            axes[0,1].set_title('Price Convergence - No numeric data available')\n",
    "        \n",
    "        # Plot premium up/down\n",
    "        if not premium_up.empty and premium_up.notna().any().any():\n",
    "            premium_up.plot(kind='bar', ax=axes[1,0], title='Premium Up')\n",
    "            axes[1,0].set_ylabel('Premium')\n",
    "            axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            axes[1,0].set_title('Premium Up - No numeric data available')\n",
    "        \n",
    "        if not premium_down.empty and premium_down.notna().any().any():\n",
    "            premium_down.plot(kind='bar', ax=axes[1,1], title='Premium Down')\n",
    "            axes[1,1].set_ylabel('Premium')\n",
    "            axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            axes[1,1].set_title('Premium Down - No numeric data available')\n",
    "        \n",
    "        # Plot demand and curtailment costs\n",
    "        if not demand_cost.empty and demand_cost.notna().any().any():\n",
    "            demand_cost.plot(kind='bar', ax=axes[2,0], title='Demand Cost')\n",
    "            axes[2,0].set_ylabel('Cost')\n",
    "            axes[2,0].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            axes[2,0].set_title('Demand Cost - No numeric data available')\n",
    "        \n",
    "        if not curtail_cost.empty and curtail_cost.notna().any().any():\n",
    "            curtail_cost.plot(kind='bar', ax=axes[2,1], title='Curtailment Cost')\n",
    "            axes[2,1].set_ylabel('Cost')\n",
    "            axes[2,1].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            axes[2,1].set_title('Curtailment Cost - No numeric data available')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating visualizations: {str(e)}\")\n",
    "\n",
    "# Example usage for visualization\n",
    "if __name__ == \"__main__\":\n",
    "    summary_file = os.path.join('Test_output_files/Results_SectionV', f\"Summary_Results_{date.today().strftime('%Y_%m_%d')}.xlsx\")\n",
    "    plot_summary_results(summary_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
