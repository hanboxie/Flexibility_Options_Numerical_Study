{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyomo.environ as pyo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime\n",
    "import ast\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DA model with Flexibility Options and Storage Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAFOModel:\n",
    "    def __init__(self, num_periods=24, num_scenarios=5, num_generators=0, num_tiers=4, num_storage=0):\n",
    "        \"\"\"\n",
    "        Initialize the DAFO model with flexible set dimensions.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        num_periods : int, optional\n",
    "            Number of time periods (default: 24)\n",
    "        num_scenarios : int, optional\n",
    "            Number of scenarios (default: 5)\n",
    "        num_generators : int, optional\n",
    "            Number of generators (if None, determined from data)\n",
    "        num_tiers : int, optional\n",
    "            Number of tiers (default: 4)\n",
    "        num_storage : int, optional\n",
    "            Number of storage units (if None, determined from data)\n",
    "        \"\"\"\n",
    "        self.num_periods = num_periods\n",
    "        self.num_scenarios = num_scenarios\n",
    "        self.num_generators = num_generators\n",
    "        self.num_tiers = num_tiers\n",
    "        self.num_storage = num_storage\n",
    "        \n",
    "        self.model = pyo.AbstractModel()\n",
    "        self._define_sets()\n",
    "        self._define_parameters()\n",
    "        self._define_variables()\n",
    "        self._define_objective()\n",
    "        self._define_constraints()\n",
    "    \n",
    "    def _define_sets(self):\n",
    "        self.model.T = pyo.RangeSet(1, self.num_periods)    # Set of time periods\n",
    "        self.model.S = pyo.RangeSet(1, self.num_scenarios)  # Set of scenarios\n",
    "        self.model.R = pyo.RangeSet(1, self.num_tiers)     # Set of tiers\n",
    "        \n",
    "        # Generator set\n",
    "        if self.num_generators > 0:\n",
    "            self.model.G = pyo.RangeSet(1, self.num_generators)\n",
    "        else:\n",
    "            self.model.G = pyo.Set()\n",
    "        \n",
    "        # Storage set\n",
    "        if self.num_storage > 0:\n",
    "            self.model.B = pyo.RangeSet(1, self.num_storage)\n",
    "        else:\n",
    "            self.model.B = pyo.Set()\n",
    "    \n",
    "    def _define_parameters(self):\n",
    "        # General Parameters\n",
    "        self.model.VC = pyo.Param(self.model.G)           # Variable cost\n",
    "        self.model.VCUP = pyo.Param(self.model.G)         # Variable cost up\n",
    "        self.model.VCDN = pyo.Param(self.model.G)         # Variable cost down\n",
    "        self.model.CAP = pyo.Param(self.model.G)          # Capacity\n",
    "        self.model.REDA = pyo.Param(self.model.T)         # Maximum DA RE for each hour\n",
    "        self.model.DEMAND = pyo.Param(self.model.T)       # Electricity demand per hour\n",
    "        self.model.D1 = pyo.Param(within=pyo.NonNegativeIntegers)    # Linear cost coefficient for demand slack\n",
    "        self.model.D2 = pyo.Param(within=pyo.NonNegativeIntegers)    # Quadratic cost coefficient for demand slack\n",
    "\n",
    "        # Parameters specific to the FO\n",
    "        self.model.RR = pyo.Param(self.model.G)                      # Ramp rate\n",
    "        self.model.RE = pyo.Param(self.model.S, self.model.T)        # Renewable generation at each scenario and time\n",
    "        self.model.PEN = pyo.Param(within=pyo.NonNegativeIntegers)   # Penalty for inadequate flexibility up\n",
    "        self.model.PENDN = pyo.Param(within=pyo.NonNegativeIntegers) # Penalty for inadequate flexibility down\n",
    "        self.model.smallM = pyo.Param(within=pyo.NonNegativeReals)   # Parameter for alternative optima\n",
    "        self.model.probTU = pyo.Param(self.model.R)                  # Probability of exercise FO up\n",
    "        self.model.probTD = pyo.Param(self.model.R)                  # Probability of exercise FO down\n",
    "\n",
    "        # Storage Parameters\n",
    "        self.model.E_MAX = pyo.Param(self.model.B)        # Maximum energy capacity\n",
    "        self.model.P_MAX = pyo.Param(self.model.B)        # Maximum power capacity\n",
    "        self.model.ETA_CH = pyo.Param(self.model.B)       # Charging efficiency\n",
    "        self.model.ETA_DCH = pyo.Param(self.model.B)      # Discharging efficiency\n",
    "        self.model.E0 = pyo.Param(self.model.B)           # Initial state of charge\n",
    "        self.model.E_FINAL = pyo.Param(self.model.B)      # Required final state of charge\n",
    "        self.model.STORAGE_COST = pyo.Param(self.model.B) # Storage operating cost per MWh\n",
    "    \n",
    "    def _define_variables(self):\n",
    "        # Energy and reserve variables\n",
    "        self.model.d = pyo.Var(self.model.T, domain=pyo.NonNegativeReals)      # Demand slack\n",
    "        self.model.rgDA = pyo.Var(self.model.T, domain=pyo.NonNegativeReals)   # DA renewables schedule\n",
    "        self.model.du = pyo.Var(self.model.S, self.model.T)                    # Demand uncertainty\n",
    "        \n",
    "        # Variables dependent on generator set\n",
    "        if len(self.model.G) > 0 or isinstance(self.model.G, pyo.RangeSet):\n",
    "            self.model.xDA = pyo.Var(self.model.G, self.model.T, domain=pyo.NonNegativeReals)  # DA energy schedule\n",
    "            # generator FO Variables\n",
    "            self.model.hsu = pyo.Var(self.model.R, self.model.G, self.model.T, domain=pyo.NonNegativeReals)  # Supply FO up\n",
    "            self.model.hsd = pyo.Var(self.model.R, self.model.G, self.model.T, domain=pyo.NonNegativeReals)  # Supply FO down\n",
    "            \n",
    "        # FO Variables independent of generators and storage\n",
    "        self.model.hdu = pyo.Var(self.model.R, self.model.T, domain=pyo.NonNegativeReals)     # Demand FO up\n",
    "        self.model.hdd = pyo.Var(self.model.R, self.model.T, domain=pyo.NonNegativeReals)     # Demand FO down\n",
    "        self.model.sdu = pyo.Var(self.model.R, self.model.T, domain=pyo.NonNegativeReals)     # Self-supply FO up\n",
    "        self.model.sdd = pyo.Var(self.model.R, self.model.T, domain=pyo.NonNegativeReals)     # Self-supply FO down\n",
    "        self.model.y = pyo.Var(self.model.S, self.model.T, domain=pyo.NonNegativeReals)       # Auxiliary variable\n",
    "\n",
    "        # Variables dependent on storage set\n",
    "        if len(self.model.B) > 0 or isinstance(self.model.B, pyo.RangeSet):\n",
    "            # Storage Variables\n",
    "            self.model.e = pyo.Var(self.model.B, self.model.T, domain=pyo.NonNegativeReals)     # Energy level\n",
    "            self.model.p_ch = pyo.Var(self.model.B, self.model.T, domain=pyo.NonNegativeReals)  # Charging power\n",
    "            self.model.p_dch = pyo.Var(self.model.B, self.model.T, domain=pyo.NonNegativeReals) # Discharging power\n",
    "            # Storage FO Variables\n",
    "            self.model.bsu = pyo.Var(self.model.R, self.model.B, self.model.T, domain=pyo.NonNegativeReals)  # Storage FO up\n",
    "            self.model.bsd = pyo.Var(self.model.R, self.model.B, self.model.T, domain=pyo.NonNegativeReals)  # Storage FO down\n",
    "    \n",
    "    def _define_objective(self):\n",
    "        # Objective function\n",
    "        def obj_expression(m):\n",
    "            objective_terms = []\n",
    "            \n",
    "            # Energy costs - generators\n",
    "            if hasattr(m, 'xDA') and len(m.G) > 0:\n",
    "                objective_terms.append(sum(m.VC[g] * m.xDA[g,t] for g in m.G for t in m.T))\n",
    "            \n",
    "            # Flexibility costs - generators\n",
    "            if hasattr(m, 'hsu') and len(m.G) > 0:\n",
    "                objective_terms.append(sum(m.probTU[r] * m.VCUP[g] * m.hsu[r,g,t] for g in m.G for r in m.R for t in m.T))\n",
    "                objective_terms.append(-sum(m.probTD[r] * m.VCDN[g] * m.hsd[r,g,t] for g in m.G for r in m.R for t in m.T))\n",
    "            \n",
    "            # Self-supply flexibility costs\n",
    "            objective_terms.append(sum(m.probTU[r] * m.PEN * m.sdu[r,t] for r in m.R for t in m.T))\n",
    "            objective_terms.append(-sum(m.probTD[r] * m.PENDN * m.sdd[r,t] for r in m.R for t in m.T))\n",
    "            \n",
    "            # Storage related costs\n",
    "            if hasattr(m, 'bsu') and len(m.B) > 0:\n",
    "                # Storage flexibility costs\n",
    "                objective_terms.append(sum(m.probTU[r] * m.STORAGE_COST[b] * m.bsu[r,b,t] for b in m.B for r in m.R for t in m.T))\n",
    "                objective_terms.append(-sum(m.probTD[r] * m.STORAGE_COST[b] * m.bsd[r,b,t] for b in m.B for r in m.R for t in m.T))\n",
    "                # Storage operation costs\n",
    "                objective_terms.append(sum(m.STORAGE_COST[b] * (m.p_ch[b,t] + m.p_dch[b,t]) for b in m.B for t in m.T))\n",
    "            \n",
    "            # Auxiliary costs\n",
    "            objective_terms.append(sum(m.y[s,t] for s in m.S for t in m.T) * m.smallM)\n",
    "            \n",
    "            # Demand response costs\n",
    "            objective_terms.append(sum(0.2 * m.D1 * (m.d[t] + m.du[s,t]) for s in m.S for t in m.T))\n",
    "            objective_terms.append(0.2 * m.D2 * sum((m.d[t] + m.du[s,t]) * (m.d[t] + m.du[s,t]) for s in m.S for t in m.T))\n",
    "            \n",
    "            return sum(objective_terms)\n",
    "\n",
    "        self.model.OBJ = pyo.Objective(rule=obj_expression)\n",
    "    \n",
    "    def _define_constraints(self):\n",
    "        # Define constraints - Numbering of constraints follows paper\n",
    "        # Energy balance for each hour\n",
    "        def DA_energy_balance(model, t):\n",
    "            gen_sum = 0\n",
    "            storage_sum = 0\n",
    "            \n",
    "            if hasattr(model, 'xDA'):\n",
    "                gen_sum = sum(model.xDA[g,t] for g in model.G) if len(model.G) > 0 else 0\n",
    "                \n",
    "            if hasattr(model, 'p_dch') and hasattr(model, 'p_ch'):\n",
    "                storage_sum = sum(model.p_dch[b,t] - model.p_ch[b,t] for b in model.B) if len(model.B) > 0 else 0\n",
    "            \n",
    "            return (gen_sum + \n",
    "                    model.rgDA[t] + \n",
    "                    storage_sum + \n",
    "                    model.d[t] == model.DEMAND[t])\n",
    "        \n",
    "        self.model.Con3 = pyo.Constraint(self.model.T, rule=DA_energy_balance)\n",
    "\n",
    "        # Flexibility balance for each hour\n",
    "        def DA_flexup_balance(model, r, t):\n",
    "            gen_flex_up = 0\n",
    "            storage_flex_up = 0\n",
    "            \n",
    "            if hasattr(model, 'hsu'):\n",
    "                gen_flex_up = sum(model.hsu[r,g,t] for g in model.G) if len(model.G) > 0 else 0\n",
    "                \n",
    "            if hasattr(model, 'bsu'):\n",
    "                storage_flex_up = sum(model.bsu[r,b,t] for b in model.B) if len(model.B) > 0 else 0\n",
    "            \n",
    "            return (gen_flex_up + storage_flex_up == model.hdu[r,t])\n",
    "        \n",
    "        self.model.Con4UP = pyo.Constraint(self.model.R, self.model.T, rule=DA_flexup_balance)\n",
    "\n",
    "        def DA_flexdn_balance(model, r, t):\n",
    "            gen_flex_down = 0\n",
    "            storage_flex_down = 0\n",
    "            \n",
    "            if hasattr(model, 'hsd'):\n",
    "                gen_flex_down = sum(model.hsd[r,g,t] for g in model.G) if len(model.G) > 0 else 0\n",
    "                \n",
    "            if hasattr(model, 'bsd'):\n",
    "                storage_flex_down = sum(model.bsd[r,b,t] for b in model.B) if len(model.B) > 0 else 0\n",
    "            \n",
    "            return (gen_flex_down + storage_flex_down == model.hdd[r,t])\n",
    "        \n",
    "        self.model.Con4DN = pyo.Constraint(self.model.R, self.model.T, rule=DA_flexdn_balance)\n",
    "\n",
    "        # Flexibility demand for each scenario and hour\n",
    "        def DA_flex_demand(model, s, t):\n",
    "            return (-model.du[s,t] + \n",
    "                    sum(model.hdd[r,t] + model.sdd[r,t] for r in model.R if r <= s-1) -\n",
    "                    sum(model.hdu[r,t] + model.sdu[r,t] for r in model.R if r >= s) == \n",
    "                    model.RE[s,t] - model.rgDA[t])\n",
    "        \n",
    "        self.model.Con6 = pyo.Constraint(self.model.S, self.model.T, rule=DA_flex_demand)\n",
    "\n",
    "        # Add generator constraints only if generators exist\n",
    "        if hasattr(self.model, 'xDA') and (len(self.model.G) > 0 or isinstance(self.model.G, pyo.RangeSet) or self.num_generators is None):\n",
    "            # Inter-temporal constraints\n",
    "            def ramp_rate_up(model, g, t):\n",
    "                if t == 1:\n",
    "                    return pyo.Constraint.Skip\n",
    "                return model.xDA[g,t] - model.xDA[g,t-1] <= model.RR[g]\n",
    "            \n",
    "            self.model.ramp_up = pyo.Constraint(self.model.G, self.model.T, rule=ramp_rate_up)\n",
    "\n",
    "            def ramp_rate_down(model, g, t):\n",
    "                if t == 1:\n",
    "                    return pyo.Constraint.Skip\n",
    "                return model.xDA[g,t-1] - model.xDA[g,t] <= model.RR[g]\n",
    "            \n",
    "            self.model.ramp_down = pyo.Constraint(self.model.G, self.model.T, rule=ramp_rate_down)\n",
    "\n",
    "            # Generation limits without commitment status\n",
    "            def generation_limits(model, g, t):\n",
    "                return model.xDA[g,t] <= model.CAP[g]\n",
    "            \n",
    "            self.model.generation_limits = pyo.Constraint(self.model.G, self.model.T, rule=generation_limits)\n",
    "\n",
    "        # Add storage constraints only if storage exists\n",
    "        if hasattr(self.model, 'e') and (len(self.model.B) > 0 or isinstance(self.model.B, pyo.RangeSet) or self.num_storage is None):\n",
    "            # Storage energy balance\n",
    "            def storage_balance(model, b, t):\n",
    "                if t == 1:\n",
    "                    return (model.e[b,t] == model.E0[b] + \n",
    "                            model.ETA_CH[b] * model.p_ch[b,t] - \n",
    "                            (1/model.ETA_DCH[b]) * model.p_dch[b,t])\n",
    "                else:\n",
    "                    return (model.e[b,t] == model.e[b,t-1] + \n",
    "                            model.ETA_CH[b] * model.p_ch[b,t] - \n",
    "                            (1/model.ETA_DCH[b]) * model.p_dch[b,t])\n",
    "\n",
    "        # Record duals for market analysis\n",
    "        self.model.dual = pyo.Suffix(direction=pyo.Suffix.IMPORT)\n",
    "        \n",
    "    def create_instance(self, data):\n",
    "        \"\"\"\n",
    "        Create a concrete instance of the model using provided data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : dict\n",
    "            Dictionary containing the data for the model parameters\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        instance : ConcreteModel\n",
    "            A concrete instance of the model\n",
    "        \"\"\"\n",
    "        return self.model.create_instance(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RT Simulation Model with Storage Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RTSimModel:\n",
    "    def __init__(self, num_periods=24, num_scenarios=5, num_generators=None, num_storage=None):\n",
    "        \"\"\"\n",
    "        Initialize the RTSim model with flexible set dimensions.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        num_periods : int, optional\n",
    "            Number of time periods (default: 24)\n",
    "        num_scenarios : int, optional\n",
    "            Number of scenarios (default: 5)\n",
    "        num_generators : int, optional\n",
    "            Number of generators (if None, determined from data)\n",
    "        num_storage : int, optional\n",
    "            Number of storage units (if None, determined from data)\n",
    "        \"\"\"\n",
    "        self.num_periods = num_periods\n",
    "        self.num_scenarios = num_scenarios\n",
    "        self.num_generators = num_generators\n",
    "        self.num_storage = num_storage\n",
    "        \n",
    "        self.model = pyo.AbstractModel()\n",
    "        self._define_sets()\n",
    "        self._define_parameters()\n",
    "        self._define_variables()\n",
    "        self._define_objective()\n",
    "        self._define_constraints()\n",
    "    \n",
    "    def _define_sets(self):\n",
    "        # Sets\n",
    "        self.model.T = pyo.RangeSet(1, self.num_periods)    # Set of time periods\n",
    "        self.model.S = pyo.RangeSet(1, self.num_scenarios)  # Set of scenarios\n",
    "        \n",
    "        # Generator set - can be determined from data\n",
    "        if self.num_generators is not None and self.num_generators > 0:\n",
    "            self.model.G = pyo.RangeSet(1, self.num_generators)\n",
    "        else:\n",
    "            self.model.G = pyo.Set()  # Will be populated when data is loaded or can be empty\n",
    "        \n",
    "        # Storage set - can be determined from data\n",
    "        if self.num_storage is not None and self.num_storage > 0:\n",
    "            self.model.B = pyo.RangeSet(1, self.num_storage)\n",
    "        else:\n",
    "            self.model.B = pyo.Set()  # Will be populated when data is loaded or can be empty\n",
    "    \n",
    "    def _define_parameters(self):\n",
    "        # Original Parameters\n",
    "        self.model.VC = pyo.Param(self.model.G)           # Variable cost\n",
    "        self.model.VCUP = pyo.Param(self.model.G)         # Variable cost up\n",
    "        self.model.VCDN = pyo.Param(self.model.G)         # Variable cost down\n",
    "        self.model.CAP = pyo.Param(self.model.G)          # Generator capacity\n",
    "        self.model.RR = pyo.Param(self.model.G)           # Ramp rate\n",
    "\n",
    "        self.model.prob = pyo.Param(self.model.S)         # Scenario probability\n",
    "        self.model.RE = pyo.Param(self.model.S, self.model.T)  # Renewable generation by scenario and time\n",
    "        self.model.DEMAND = pyo.Param(self.model.T)       # Hourly demand\n",
    "        self.model.D1 = pyo.Param(within=pyo.NonNegativeIntegers)  # Linear demand cost coefficient\n",
    "        self.model.D2 = pyo.Param(within=pyo.NonNegativeIntegers)  # Quadratic demand cost coefficient\n",
    "        self.model.xDA = pyo.Param(self.model.G, self.model.T) # DA schedule by generator and time\n",
    "        self.model.REDA = pyo.Param(self.model.T)         # DA renewable schedule by time\n",
    "        self.model.PEN = pyo.Param(within=pyo.NonNegativeIntegers)   # Upward penalty\n",
    "        self.model.PENDN = pyo.Param()                    # Downward penalty\n",
    "        self.model.DAdr = pyo.Param(self.model.T)         # DA demand response by time\n",
    "\n",
    "        # Storage Parameters\n",
    "        self.model.E_MAX = pyo.Param(self.model.B)        # Maximum energy capacity\n",
    "        self.model.P_MAX = pyo.Param(self.model.B)        # Maximum power capacity\n",
    "        self.model.ETA_CH = pyo.Param(self.model.B)       # Charging efficiency\n",
    "        self.model.ETA_DCH = pyo.Param(self.model.B)      # Discharging efficiency\n",
    "        self.model.E0 = pyo.Param(self.model.B)           # Initial state of charge\n",
    "        self.model.STORAGE_COST = pyo.Param(self.model.B)  # Operating cost per MWh of throughput\n",
    "        self.model.E_FINAL = pyo.Param(self.model.B)      # Required final state of charge\n",
    "        \n",
    "        # Storage DA parameters\n",
    "        self.model.e_DA = pyo.Param(self.model.B, self.model.T)  # DA energy level\n",
    "        self.model.p_ch_DA = pyo.Param(self.model.B, self.model.T)  # DA charging\n",
    "        self.model.p_dch_DA = pyo.Param(self.model.B, self.model.T)  # DA discharging\n",
    "    \n",
    "    def _define_variables(self):\n",
    "        # Variables that depend on generators\n",
    "        if len(self.model.G) > 0 or isinstance(self.model.G, pyo.RangeSet) or self.num_generators is None:\n",
    "            # RT adjustment variables for each scenario and time\n",
    "            self.model.xup = pyo.Var(self.model.S, self.model.G, self.model.T, domain=pyo.NonNegativeReals)  # Generator up adjustment\n",
    "            self.model.xdn = pyo.Var(self.model.S, self.model.G, self.model.T, domain=pyo.NonNegativeReals)  # Generator down adjustment\n",
    "        \n",
    "        # Variables independent of generators and storage\n",
    "        self.model.d = pyo.Var(self.model.S, self.model.T)     # RT demand response\n",
    "        self.model.rgup = pyo.Var(self.model.S, self.model.T, domain=pyo.NonNegativeReals)  # RE up adjustment\n",
    "        self.model.rgdn = pyo.Var(self.model.S, self.model.T, domain=pyo.NonNegativeReals)  # RE down adjustment\n",
    "        self.model.sdup = pyo.Var(self.model.S, self.model.T, domain=pyo.NonNegativeReals)  # Shortage\n",
    "        self.model.sddn = pyo.Var(self.model.S, self.model.T, domain=pyo.NonNegativeReals)  # Surplus\n",
    "\n",
    "        # Variables that depend on storage\n",
    "        if len(self.model.B) > 0 or isinstance(self.model.B, pyo.RangeSet) or self.num_storage is None:\n",
    "            # Storage Variables\n",
    "            self.model.e = pyo.Var(self.model.S, self.model.B, self.model.T, domain=pyo.NonNegativeReals)     # Energy level\n",
    "            self.model.p_ch = pyo.Var(self.model.S, self.model.B, self.model.T, domain=pyo.NonNegativeReals)  # Charging power\n",
    "            self.model.p_dch = pyo.Var(self.model.S, self.model.B, self.model.T, domain=pyo.NonNegativeReals) # Discharging power\n",
    "            self.model.b_up = pyo.Var(self.model.S, self.model.B, self.model.T, domain=pyo.NonNegativeReals)  # Storage up adjustment\n",
    "            self.model.b_dn = pyo.Var(self.model.S, self.model.B, self.model.T, domain=pyo.NonNegativeReals)  # Storage down adjustment\n",
    "    \n",
    "    def _define_objective(self):\n",
    "        # Objective Function\n",
    "        def obj_expression(m):\n",
    "            objective_terms = []\n",
    "            \n",
    "            for s in m.S:\n",
    "                scenario_terms = []\n",
    "                \n",
    "                # Generator adjustment costs - only if generators exist\n",
    "                if hasattr(m, 'xup') and len(m.G) > 0:\n",
    "                    scenario_terms.append(\n",
    "                        sum(m.VCUP[g] * m.xup[s,g,t] - m.VCDN[g] * m.xdn[s,g,t] for g in m.G for t in m.T)\n",
    "                    )\n",
    "                \n",
    "                # Shortage/surplus penalties\n",
    "                scenario_terms.append(m.PENDN * sum(m.sdup[s,t] for t in m.T))\n",
    "                scenario_terms.append(m.PEN * sum(m.sddn[s,t] for t in m.T))\n",
    "                \n",
    "                # Demand response costs\n",
    "                scenario_terms.append(\n",
    "                    sum((m.D1 * (m.DAdr[t] + m.d[s,t]) + \n",
    "                         m.D2 * (m.DAdr[t] + m.d[s,t]) * (m.DAdr[t] + m.d[s,t])) for t in m.T)\n",
    "                )\n",
    "                scenario_terms.append(\n",
    "                    -sum((m.D1 * m.DAdr[t] + m.D2 * m.DAdr[t] * m.DAdr[t]) for t in m.T)\n",
    "                )\n",
    "                \n",
    "                # Storage operating costs - only if storage exists\n",
    "                if hasattr(m, 'p_ch') and len(m.B) > 0:\n",
    "                    scenario_terms.append(\n",
    "                        sum(m.STORAGE_COST[b] * (m.p_ch[s,b,t] + m.p_dch[s,b,t]) for b in m.B for t in m.T)\n",
    "                    )\n",
    "                \n",
    "                # Add the weighted scenario terms to the overall objective\n",
    "                objective_terms.append(m.prob[s] * sum(scenario_terms))\n",
    "            \n",
    "            return sum(objective_terms)\n",
    "\n",
    "        self.model.OBJ = pyo.Objective(rule=obj_expression)\n",
    "    \n",
    "    def _define_constraints(self):\n",
    "        # RT energy balance for each scenario and time period\n",
    "        def RT_energy_balance(model, s, t):\n",
    "            gen_adjustment = 0\n",
    "            storage_adjustment = 0\n",
    "            \n",
    "            # Generator adjustments - only if generators exist\n",
    "            if hasattr(model, 'xup') and len(model.G) > 0:\n",
    "                gen_adjustment = sum(model.xup[s,g,t] - model.xdn[s,g,t] for g in model.G)\n",
    "            \n",
    "            # Storage adjustments - only if storage exists\n",
    "            if hasattr(model, 'p_ch') and len(model.B) > 0:\n",
    "                storage_adjustment = sum(\n",
    "                    model.p_dch[s,b,t] - model.p_ch[s,b,t] - \n",
    "                    model.p_dch_DA[b,t] + model.p_ch_DA[b,t] for b in model.B\n",
    "                )\n",
    "            \n",
    "            return (gen_adjustment +\n",
    "                    model.rgup[s,t] - model.rgdn[s,t] +\n",
    "                    storage_adjustment +\n",
    "                    model.d[s,t] == 0)\n",
    "                    \n",
    "        self.model.Con3 = pyo.Constraint(self.model.S, self.model.T, rule=RT_energy_balance)\n",
    "\n",
    "        # RT renewable availability\n",
    "        def RT_RE_availability(model, s, t):\n",
    "            return (model.rgup[s,t] - model.rgdn[s,t] + model.sdup[s,t] - model.sddn[s,t] == \n",
    "                    model.RE[s,t] - model.REDA[t])\n",
    "                    \n",
    "        self.model.Con4 = pyo.Constraint(self.model.S, self.model.T, rule=RT_RE_availability)\n",
    "\n",
    "        # Generator constraints - only if generators exist\n",
    "        if hasattr(self.model, 'xup') and (len(self.model.G) > 0 or isinstance(self.model.G, pyo.RangeSet) or self.num_generators is None):\n",
    "            # Generator ramping constraints\n",
    "            def RT_ramp_up(model, s, g, t):\n",
    "                return model.xup[s,g,t] <= model.RR[g]\n",
    "                \n",
    "            self.model.Con5up = pyo.Constraint(self.model.S, self.model.G, self.model.T, rule=RT_ramp_up)\n",
    "\n",
    "            def RT_ramp_dn(model, s, g, t):\n",
    "                return model.xdn[s,g,t] <= model.RR[g]\n",
    "                \n",
    "            self.model.Con5dn = pyo.Constraint(self.model.S, self.model.G, self.model.T, rule=RT_ramp_dn)\n",
    "\n",
    "            # Generator capacity constraints\n",
    "            def RT_capacity_cons(model, s, g, t):\n",
    "                return model.xDA[g,t] + model.xup[s,g,t] <= model.CAP[g]\n",
    "                \n",
    "            self.model.Con6 = pyo.Constraint(self.model.S, self.model.G, self.model.T, rule=RT_capacity_cons)\n",
    "\n",
    "            def RT_capacity_min(model, s, g, t):\n",
    "                return model.xDA[g,t] - model.xdn[s,g,t] >= 0\n",
    "                \n",
    "            self.model.Con7 = pyo.Constraint(self.model.S, self.model.G, self.model.T, rule=RT_capacity_min)\n",
    "\n",
    "        # Storage Constraints - only if storage exists\n",
    "        if hasattr(self.model, 'e') and (len(self.model.B) > 0 or isinstance(self.model.B, pyo.RangeSet) or self.num_storage is None):\n",
    "            # Storage energy balance\n",
    "            def storage_balance(model, s, b, t):\n",
    "                if t == 1:\n",
    "                    return (model.e[s,b,t] == model.E0[b] + \n",
    "                            model.ETA_CH[b] * model.p_ch[s,b,t] - \n",
    "                            (1/model.ETA_DCH[b]) * model.p_dch[s,b,t])\n",
    "                return (model.e[s,b,t] == model.e[s,b,t-1] + \n",
    "                        model.ETA_CH[b] * model.p_ch[s,b,t] - \n",
    "                        (1/model.ETA_DCH[b]) * model.p_dch[s,b,t])\n",
    "                        \n",
    "            self.model.storage_balance = pyo.Constraint(self.model.S, self.model.B, self.model.T, rule=storage_balance)\n",
    "\n",
    "            # Storage capacity constraint\n",
    "            def storage_capacity(model, s, b, t):\n",
    "                return model.e[s,b,t] <= model.E_MAX[b]\n",
    "                \n",
    "            self.model.storage_capacity = pyo.Constraint(self.model.S, self.model.B, self.model.T, rule=storage_capacity)\n",
    "\n",
    "            # Power limits\n",
    "            def power_limits(model, s, b, t):\n",
    "                return model.p_ch[s,b,t] + model.p_dch[s,b,t] <= model.P_MAX[b]\n",
    "                \n",
    "            self.model.power_limits = pyo.Constraint(self.model.S, self.model.B, self.model.T, rule=power_limits)\n",
    "            \n",
    "            # Storage adjustment limits\n",
    "            def storage_adjustment_limits(model, s, b, t):\n",
    "                return model.b_up[s,b,t] + model.b_dn[s,b,t] <= 0.5 * model.P_MAX[b]\n",
    "                \n",
    "            self.model.storage_adjustment_limits = pyo.Constraint(self.model.S, self.model.B, self.model.T, \n",
    "                                                                rule=storage_adjustment_limits)\n",
    "\n",
    "            # Final state of charge requirement\n",
    "            def final_soc(model, s, b):\n",
    "                return model.e[s,b,self.num_periods] >= model.E_FINAL[b]\n",
    "                \n",
    "            self.model.final_soc = pyo.Constraint(self.model.S, self.model.B, rule=final_soc)\n",
    "\n",
    "            # Storage ramping constraints\n",
    "            def storage_ramp_rate(model, s, b, t):\n",
    "                if t == 1:\n",
    "                    return pyo.Constraint.Skip\n",
    "                # This constraint with 'abs' needs to be reformulated for a solver\n",
    "                # Here's a simple reformulation with two constraints\n",
    "                return [\n",
    "                    model.p_ch[s,b,t] - model.p_ch[s,b,t-1] <= 0.25 * model.P_MAX[b],\n",
    "                    model.p_ch[s,b,t-1] - model.p_ch[s,b,t] <= 0.25 * model.P_MAX[b],\n",
    "                    model.p_dch[s,b,t] - model.p_dch[s,b,t-1] <= 0.25 * model.P_MAX[b],\n",
    "                    model.p_dch[s,b,t-1] - model.p_dch[s,b,t] <= 0.25 * model.P_MAX[b]\n",
    "                ]\n",
    "                        \n",
    "            self.model.storage_ramp = pyo.Constraint(self.model.S, self.model.B, self.model.T, rule=storage_ramp_rate)\n",
    "\n",
    "        # Record duals\n",
    "        self.model.dual = pyo.Suffix(direction=pyo.Suffix.IMPORT)\n",
    "        \n",
    "    def create_instance(self, data):\n",
    "        \"\"\"\n",
    "        Create a concrete instance of the model using provided data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : dict\n",
    "            Dictionary containing the data for the model parameters\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        instance : ConcreteModel\n",
    "            A concrete instance of the model\n",
    "        \"\"\"\n",
    "        return self.model.create_instance(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, csv_path):\n",
    "        self.csv_path = csv_path\n",
    "        self.df = None\n",
    "        self.time_periods = range(1, 25)  # 24 hour periods\n",
    "        self.hour_mapping = {\n",
    "            '0800': 1, '0900': 2, '1000': 3, '1100': 4, '1200': 5, '1300': 6,\n",
    "            '1400': 7, '1500': 8, '1600': 9, '1700': 10, '1800': 11, '1900': 12,\n",
    "            '2000': 13, '2100': 14, '2200': 15, '2300': 16, '0000': 17, '0100': 18,\n",
    "            '0200': 19, '0300': 20, '0400': 21, '0500': 22, '0600': 23, '0700': 24\n",
    "        }\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data\"\"\"\n",
    "        try:\n",
    "            self.df = pd.read_csv(self.csv_path)\n",
    "            \n",
    "            # Reorder columns to match time periods\n",
    "            hour_cols = [col for col in self.df.columns if col in self.hour_mapping]\n",
    "            ordered_cols = sorted(hour_cols, key=lambda x: self.hour_mapping[x])\n",
    "            self.df_ordered = self.df[['Type', 'Index'] + ordered_cols] if 'Type' in self.df.columns and 'Index' in self.df.columns else self.df\n",
    "            \n",
    "            return self.df_ordered\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {str(e)}\")\n",
    "            # Create a minimal dataframe if file doesn't exist or is invalid\n",
    "            self.df = pd.DataFrame({'Type': ['Forecast', 'Actual'], 'Index': [1, 1]})\n",
    "            for hour in self.hour_mapping.keys():\n",
    "                self.df[hour] = 1.0  # Default values\n",
    "            self.df_ordered = self.df\n",
    "            return self.df_ordered\n",
    "\n",
    "    def prepare_da_data(self, forecast_horizon=24):\n",
    "        \"\"\"Prepare data for DA model including storage parameters\"\"\"\n",
    "        if self.df is None:\n",
    "            self.load_data()\n",
    "\n",
    "        # Filter for forecast data or use first row if not present\n",
    "        if 'Type' in self.df.columns:\n",
    "            da_data = self.df[self.df['Type'] == 'Forecast'].copy()\n",
    "            if da_data.empty:\n",
    "                da_data = self.df.iloc[[0]].copy()\n",
    "        else:\n",
    "            da_data = self.df.iloc[[0]].copy()\n",
    "        \n",
    "        # Create DA parameter dictionary\n",
    "        da_params = {\n",
    "            'DEMAND': {t: 1.0 for t in self.time_periods}  # Default values\n",
    "        }\n",
    "        \n",
    "        # Try to populate with actual data if available\n",
    "        try:\n",
    "            for col, t in self.hour_mapping.items():\n",
    "                if col in da_data.columns:\n",
    "                    da_params['DEMAND'][t] = float(da_data.iloc[0][col])\n",
    "        except Exception as e:\n",
    "            print(f\"Error preparing DA demand data: {str(e)}\")\n",
    "        \n",
    "        da_params['REDA'] = {t: 0.0 for t in self.time_periods}  # Initialize with zeros\n",
    "        \n",
    "        # Add generator parameters\n",
    "        da_params.update(self.generate_generator_params())\n",
    "        \n",
    "        # Add storage parameters\n",
    "        da_params.update(self.generate_storage_params())\n",
    "        \n",
    "        # Add FO parameters\n",
    "        da_params.update(self.generate_fo_params())\n",
    "        \n",
    "        return da_params\n",
    "\n",
    "    def prepare_rt_data(self, num_scenarios=5):\n",
    "        \"\"\"Prepare data for RT model with scenario generation\"\"\"\n",
    "        if self.df is None:\n",
    "            self.load_data()\n",
    "\n",
    "        # Generate synthetic scenarios if actual data not available\n",
    "        scenarios = {}\n",
    "        for s in range(1, num_scenarios + 1):\n",
    "            scenarios[s] = {t: 1.0 for t in self.time_periods}  # Default values\n",
    "            \n",
    "        # Try to use actual data if available\n",
    "        if 'Type' in self.df.columns:\n",
    "            rt_data = self.df[self.df['Type'] == 'Actual'].copy()\n",
    "            if not rt_data.empty:\n",
    "                # Try to populate scenarios with actual data\n",
    "                try:\n",
    "                    for s in range(1, min(num_scenarios, len(rt_data)) + 1):\n",
    "                        for col, t in self.hour_mapping.items():\n",
    "                            if col in rt_data.columns and s <= len(rt_data):\n",
    "                                scenarios[s][t] = float(rt_data.iloc[s-1][col])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing scenario data: {str(e)}\")\n",
    "\n",
    "        # Create RT parameter dictionary\n",
    "        rt_params = {\n",
    "            'RE': scenarios,\n",
    "            'prob': {s: 1.0/num_scenarios for s in range(1, num_scenarios + 1)},\n",
    "            'DEMAND': {t: 1.0 for t in self.time_periods}  # Default demand\n",
    "        }\n",
    "        \n",
    "        # Try to populate RT demand from first scenario if available\n",
    "        try:\n",
    "            if 'Type' in self.df.columns:\n",
    "                rt_data = self.df[self.df['Type'] == 'Actual'].copy()\n",
    "                if not rt_data.empty:\n",
    "                    for col, t in self.hour_mapping.items():\n",
    "                        if col in rt_data.columns:\n",
    "                            rt_params['DEMAND'][t] = float(rt_data.iloc[0][col])\n",
    "        except Exception as e:\n",
    "            print(f\"Error preparing RT demand: {str(e)}\")\n",
    "\n",
    "        # Add generator parameters\n",
    "        rt_params.update(self.generate_generator_params())\n",
    "        \n",
    "        # Add storage parameters\n",
    "        rt_params.update(self.generate_storage_params())\n",
    "        \n",
    "        return rt_params\n",
    "\n",
    "    def generate_generator_params(self, num_generators=5):\n",
    "        \"\"\"Generate default generator parameters\"\"\"\n",
    "        generator_params = {\n",
    "            'CAP': {g: 100.0 if g == 1 else 20.0 for g in range(1, num_generators + 1)},  # MW\n",
    "            'VC': {g: 20.0 + 10.0 * (g-1) for g in range(1, num_generators + 1)},  # $/MWh\n",
    "            'VCUP': {g: 30.0 + 15.0 * (g-1) for g in range(1, num_generators + 1)},  # $/MWh\n",
    "            'VCDN': {g: 10.0 + 5.0 * (g-1) for g in range(1, num_generators + 1)},  # $/MWh\n",
    "            'RR': {g: 20.0 if g == 1 else 10.0 for g in range(1, num_generators + 1)},  # MW/hour\n",
    "            'MIN_UP_TIME': {g: 1 for g in range(1, num_generators + 1)},  # Hours\n",
    "            'MIN_DOWN_TIME': {g: 1 for g in range(1, num_generators + 1)},  # Hours\n",
    "            'STARTUP_COST': {g: 100.0 + 50.0 * (g-1) for g in range(1, num_generators + 1)},  # $\n",
    "            'SHUTDOWN_COST': {g: 50.0 + 25.0 * (g-1) for g in range(1, num_generators + 1)},  # $\n",
    "            'INITIAL_STATUS': {g: 1 for g in range(1, num_generators + 1)}  # All units initially on\n",
    "        }\n",
    "        return generator_params\n",
    "\n",
    "    def generate_storage_params(self, num_storage_units=3):\n",
    "        \"\"\"Generate default storage parameters\"\"\"\n",
    "        storage_params = {\n",
    "            'E_MAX': {b: 1000.0 for b in range(1, num_storage_units + 1)},  # MWh\n",
    "            'P_MAX': {b: 200.0 for b in range(1, num_storage_units + 1)},   # MW\n",
    "            'ETA_CH': {b: 0.95 for b in range(1, num_storage_units + 1)},   # charging efficiency\n",
    "            'ETA_DCH': {b: 0.95 for b in range(1, num_storage_units + 1)},  # discharging efficiency\n",
    "            'E0': {b: 500.0 for b in range(1, num_storage_units + 1)},      # initial SOC\n",
    "            'E_FINAL': {b: 500.0 for b in range(1, num_storage_units + 1)}, # final SOC requirement\n",
    "            'STORAGE_COST': {b: 5.0 for b in range(1, num_storage_units + 1)} # $/MWh operating cost\n",
    "        }\n",
    "        return storage_params\n",
    "    \n",
    "    def generate_fo_params(self, num_tiers=4):\n",
    "        \"\"\"Generate default FO parameters\"\"\"\n",
    "        fo_params = {\n",
    "            'D1': {None: 10},  # Linear cost coefficient for demand slack\n",
    "            'D2': {None: 0.1}, # Quadratic cost coefficient for demand slack\n",
    "            'PEN': {None: 500}, # Penalty for inadequate flexibility up\n",
    "            'PENDN': {None: 200}, # Penalty for inadequate flexibility down\n",
    "            'smallM': {None: 0.0001}, # Parameter for alternative optima\n",
    "            'probTU': {r: 0.2 + 0.1 * (r-1) for r in range(1, num_tiers + 1)}, # Probabilities of exercising FO up\n",
    "            'probTD': {r: 0.2 + 0.1 * (r-1) for r in range(1, num_tiers + 1)}  # Probabilities of exercising FO down\n",
    "        }\n",
    "        return fo_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSolver:\n",
    "    def __init__(self, solver_path=None):\n",
    "        \"\"\"Initialize the model solver with optional solver path\"\"\"\n",
    "        self.solver_path = solver_path\n",
    "        self.opt = self._setup_solver()\n",
    "        \n",
    "    def _setup_solver(self):\n",
    "        \"\"\"Setup the solver using CPLEX\"\"\"\n",
    "        try:\n",
    "            if self.solver_path:\n",
    "                opt = pyo.SolverFactory('cplex', executable=self.solver_path)    \n",
    "            else:\n",
    "                opt = pyo.SolverFactory('cplex')\n",
    "                    \n",
    "            if not opt.available():\n",
    "                print(\"ERROR: CPLEX is unavailable. Please check installation.\")\n",
    "                return None\n",
    "               \n",
    "            return opt\n",
    "        except Exception as e:\n",
    "            print(f\"Error setting up solver: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def solve_da_model(self, da_data):\n",
    "        \"\"\"Solve the DA model with Flexibility Options\"\"\"\n",
    "        try:\n",
    "            # Create DAFOModel instance\n",
    "            dafo_model = DAFOModel()\n",
    "            \n",
    "            # Fix data structure to ensure it's compatible with Pyomo models\n",
    "            fixed_data = self._fix_data_structure(da_data)\n",
    "            \n",
    "            # Create model instance\n",
    "            instance = dafo_model.model.create_instance({None: fixed_data})\n",
    "            print(\"DA model instance created successfully\")\n",
    "            \n",
    "            # Solve model\n",
    "            result = self.solve_with_handling(instance)\n",
    "            \n",
    "            if result:\n",
    "                # Store key outputs\n",
    "                outputs = self._extract_da_outputs(instance)\n",
    "                return instance, outputs\n",
    "            else:\n",
    "                print(\"Failed to solve DA model\")\n",
    "                return None, None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in DA model: {str(e)}\")\n",
    "            return None, None\n",
    "    \n",
    "    def solve_rt_model(self, rt_data, da_outputs=None):\n",
    "        \"\"\"Solve the RT model for each scenario\"\"\"\n",
    "        try:\n",
    "            # Create RTSimModel instance\n",
    "            rtsim_model = RTSimModel()\n",
    "            \n",
    "            # Fix data structure\n",
    "            fixed_data = self._fix_data_structure(rt_data)\n",
    "            \n",
    "            # Add DA outputs to RT data if provided\n",
    "            if da_outputs:\n",
    "                for key, value in da_outputs.items():\n",
    "                    if key not in fixed_data:\n",
    "                        fixed_data[key] = value\n",
    "            \n",
    "            # Create model instance\n",
    "            instance = rtsim_model.model.create_instance({None: fixed_data})\n",
    "            print(\"RT model instance created successfully\")\n",
    "            \n",
    "            # Solve model\n",
    "            result = self.solve_with_handling(instance)\n",
    "            \n",
    "            if result:\n",
    "                # Store key outputs\n",
    "                outputs = self._extract_rt_outputs(instance)\n",
    "                return instance, outputs\n",
    "            else:\n",
    "                print(\"Failed to solve RT model\")\n",
    "                return None, None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in RT model: {str(e)}\")\n",
    "            return None, None\n",
    "    \n",
    "    def solve_with_handling(self, model):\n",
    "        \"\"\"Solve a Pyomo model with error handling\"\"\"\n",
    "        try:\n",
    "            result = self.opt.solve(model, tee=True)\n",
    "            \n",
    "            if (result.solver.status == pyo.SolverStatus.ok and \n",
    "                result.solver.termination_condition == pyo.TerminationCondition.optimal):\n",
    "                print(\"Model solved successfully\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"Solver status: {result.solver.status}\")\n",
    "                print(f\"Termination condition: {result.solver.termination_condition}\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error solving model: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def _fix_data_structure(self, data_dict):\n",
    "        \"\"\"Fix common issues with data structure for Pyomo models\"\"\"\n",
    "        fixed_data = {}\n",
    "        \n",
    "        # Ensure all required parameters exist with proper structure\n",
    "        for param in ['DEMAND', 'D1', 'D2', 'PEN', 'PENDN', 'smallM']:\n",
    "            if param not in data_dict:\n",
    "                # Add default values based on parameter type\n",
    "                if param in ['D1', 'D2', 'PEN', 'PENDN']:\n",
    "                    fixed_data[param] = {None: 10}  # Default penalty values as mapping\n",
    "                elif param == 'smallM':\n",
    "                    fixed_data[param] = {None: 0.0001}  # Default small value for smallM\n",
    "                else:\n",
    "                    fixed_data[param] = {t: 1.0 for t in range(1, 25)}  # Default hourly values\n",
    "        \n",
    "        # Process each parameter in the input data\n",
    "        for param, value in data_dict.items():\n",
    "            # Skip None values\n",
    "            if value is None:\n",
    "                continue\n",
    "                \n",
    "            # Handle scalar parameters - convert to mapping type\n",
    "            if param in ['D1', 'D2', 'PEN', 'PENDN', 'smallM']:\n",
    "                fixed_data[param] = {None: float(value) if isinstance(value, (int, float, str)) else \n",
    "                                        (10.0 if param != 'smallM' else 0.0001)}\n",
    "            \n",
    "            # Handle indexed parameters\n",
    "            elif isinstance(value, dict):\n",
    "                # Ensure the dict keys are correct format\n",
    "                fixed_data[param] = {\n",
    "                    int(k) if isinstance(k, str) and k.isdigit() else k: v \n",
    "                    for k, v in value.items()\n",
    "                }\n",
    "            \n",
    "            # Handle other cases - convert to mapping type\n",
    "            else:\n",
    "                fixed_data[param] = {None: value}\n",
    "        \n",
    "        # Ensure RE parameter has correct structure (scenario, time)\n",
    "        if 'RE' not in fixed_data:\n",
    "            fixed_data['RE'] = {(s, t): 0.0 for s in range(1, 6) for t in range(1, 25)}\n",
    "            \n",
    "        return fixed_data\n",
    "    \n",
    "    def _extract_da_outputs(self, instance):\n",
    "        \"\"\"Extract key outputs from DA model instance\"\"\"\n",
    "        outputs = {}\n",
    "        \n",
    "        try:\n",
    "            # Extract energy schedules\n",
    "            outputs['xDA'] = {(g, t): instance.xDA[g, t].value for g in instance.G for t in instance.T}\n",
    "            \n",
    "            # Extract renewable schedule\n",
    "            outputs['REDA'] = {t: instance.rgDA[t].value for t in instance.T}\n",
    "            \n",
    "            # Extract storage schedules\n",
    "            outputs['e_DA'] = {(b, t): instance.e[b, t].value for b in instance.B for t in instance.T}\n",
    "            outputs['p_ch_DA'] = {(b, t): instance.p_ch[b, t].value for b in instance.B for t in instance.T}\n",
    "            outputs['p_dch_DA'] = {(b, t): instance.p_dch[b, t].value for b in instance.B for t in instance.T}\n",
    "            \n",
    "            # Extract FO schedules for all suppliers (generators + storage)\n",
    "            outputs['hsu'] = {(r, g, t): instance.hsu[r, g, t].value for r in instance.R for g in instance.G for t in instance.T}\n",
    "            outputs['hsd'] = {(r, g, t): instance.hsd[r, g, t].value for r in instance.R for g in instance.G for t in instance.T}\n",
    "            outputs['bsu'] = {(r, b, t): instance.bsu[r, b, t].value for r in instance.R for b in instance.B for t in instance.T}\n",
    "            outputs['bsd'] = {(r, b, t): instance.bsd[r, b, t].value for r in instance.R for b in instance.B for t in instance.T}\n",
    "            \n",
    "            # Extract FO demand\n",
    "            outputs['hdu'] = {(r, t): instance.hdu[r, t].value for r in instance.R for t in instance.T}\n",
    "            outputs['hdd'] = {(r, t): instance.hdd[r, t].value for r in instance.R for t in instance.T}\n",
    "            \n",
    "            # Extract prices\n",
    "            outputs['DA_price'] = {t: instance.dual[instance.Con3[t]] for t in instance.T}\n",
    "            outputs['FO_up_price'] = {(r, t): instance.dual[instance.Con4UP[r, t]] for r in instance.R for t in instance.T}\n",
    "            outputs['FO_down_price'] = {(r, t): instance.dual[instance.Con4DN[r, t]] for r in instance.R for t in instance.T}\n",
    "            \n",
    "            # Extract total costs\n",
    "            outputs['total_cost'] = instance.OBJ()\n",
    "            \n",
    "            # Extract commitment status\n",
    "            outputs['u'] = {(g, t): instance.u[g, t].value for g in instance.G for t in instance.T}\n",
    "            \n",
    "            # Extract demand slack\n",
    "            outputs['DAdr'] = {t: instance.d[t].value for t in instance.T}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting DA outputs: {str(e)}\")\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def _extract_rt_outputs(self, instance):\n",
    "        \"\"\"Extract key outputs from RT model instance\"\"\"\n",
    "        outputs = {}\n",
    "        \n",
    "        try:\n",
    "            # Extract RT energy adjustments\n",
    "            outputs['xup'] = {(s, g, t): instance.xup[s, g, t].value for s in instance.S for g in instance.G for t in instance.T}\n",
    "            outputs['xdn'] = {(s, g, t): instance.xdn[s, g, t].value for s in instance.S for g in instance.G for t in instance.T}\n",
    "            \n",
    "            # Extract storage adjustments\n",
    "            outputs['e_RT'] = {(s, b, t): instance.e[s, b, t].value for s in instance.S for b in instance.B for t in instance.T}\n",
    "            outputs['p_ch_RT'] = {(s, b, t): instance.p_ch[s, b, t].value for s in instance.S for b in instance.B for t in instance.T}\n",
    "            outputs['p_dch_RT'] = {(s, b, t): instance.p_dch[s, b, t].value for s in instance.S for b in instance.B for t in instance.T}\n",
    "            outputs['b_up'] = {(s, b, t): instance.b_up[s, b, t].value for s in instance.S for b in instance.B for t in instance.T}\n",
    "            outputs['b_dn'] = {(s, b, t): instance.b_dn[s, b, t].value for s in instance.S for b in instance.B for t in instance.T}\n",
    "            \n",
    "            # Extract RE adjustments\n",
    "            outputs['rgup'] = {(s, t): instance.rgup[s, t].value for s in instance.S for t in instance.T}\n",
    "            outputs['rgdn'] = {(s, t): instance.rgdn[s, t].value for s in instance.S for t in instance.T}\n",
    "            \n",
    "            # Extract shortage/surplus\n",
    "            outputs['sdup'] = {(s, t): instance.sdup[s, t].value for s in instance.S for t in instance.T}\n",
    "            outputs['sddn'] = {(s, t): instance.sddn[s, t].value for s in instance.S for t in instance.T}\n",
    "            \n",
    "            # Extract RT prices\n",
    "            outputs['RT_price'] = {(s, t): instance.dual[instance.Con3[s, t]] for s in instance.S for t in instance.T}\n",
    "            \n",
    "            # Extract total costs per scenario\n",
    "            outputs['scenario_costs'] = {s: sum(\n",
    "                instance.prob[s] * (\n",
    "                    sum(instance.VCUP[g] * instance.xup[s, g, t].value - \n",
    "                        instance.VCDN[g] * instance.xdn[s, g, t].value \n",
    "                        for g in instance.G for t in instance.T)\n",
    "                )) for s in instance.S}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting RT outputs: {str(e)}\")\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "\n",
    "class ResultsAnalyzer:\n",
    "    \"\"\"Class for analyzing and visualizing results\"\"\"\n",
    "    \n",
    "    def __init__(self, da_outputs, rt_outputs):\n",
    "        \"\"\"Initialize with outputs from DA and RT models\"\"\"\n",
    "        self.da_outputs = da_outputs\n",
    "        self.rt_outputs = rt_outputs\n",
    "        \n",
    "    def hourly_analysis(self):\n",
    "        \"\"\"Perform hourly analysis of results\"\"\"\n",
    "        # Create DataFrame for hourly results\n",
    "        hourly_results = pd.DataFrame(index=range(1, 25))\n",
    "        \n",
    "        # Add DA energy prices\n",
    "        if 'DA_price' in self.da_outputs:\n",
    "            hourly_results['DA_price'] = pd.Series(self.da_outputs['DA_price'])\n",
    "        \n",
    "        # Add RT energy prices (average across scenarios)\n",
    "        if 'RT_price' in self.rt_outputs:\n",
    "            rt_prices = pd.DataFrame.from_dict({t: [self.rt_outputs['RT_price'].get((s, t), 0) \n",
    "                                                  for s in range(1, 6)] \n",
    "                                            for t in range(1, 25)}, \n",
    "                                           orient='index')\n",
    "            hourly_results['RT_price_mean'] = rt_prices.mean(axis=1)\n",
    "            hourly_results['RT_price_min'] = rt_prices.min(axis=1)\n",
    "            hourly_results['RT_price_max'] = rt_prices.max(axis=1)\n",
    "        \n",
    "        # Add generator schedules\n",
    "        for g in range(1, 6):\n",
    "            g_schedule = pd.Series({t: self.da_outputs['xDA'].get((g, t), 0) for t in range(1, 25)})\n",
    "            hourly_results[f'Gen_{g}_DA'] = g_schedule\n",
    "        \n",
    "        # Add storage schedules\n",
    "        for b in range(1, 4):\n",
    "            b_charge = pd.Series({t: self.da_outputs['p_ch_DA'].get((b, t), 0) for t in range(1, 25)})\n",
    "            b_discharge = pd.Series({t: self.da_outputs['p_dch_DA'].get((b, t), 0) for t in range(1, 25)})\n",
    "            b_energy = pd.Series({t: self.da_outputs['e_DA'].get((b, t), 0) for t in range(1, 25)})\n",
    "            \n",
    "            hourly_results[f'Storage_{b}_charge'] = b_charge\n",
    "            hourly_results[f'Storage_{b}_discharge'] = b_discharge\n",
    "            hourly_results[f'Storage_{b}_energy'] = b_energy\n",
    "        \n",
    "        # Add FO volumes by tier\n",
    "        for r in range(1, 5):\n",
    "            # Sum FO up/down volumes across all suppliers for each tier\n",
    "            fo_up = pd.Series({t: sum(self.da_outputs['hsu'].get((r, g, t), 0) for g in range(1, 6)) + \n",
    "                                  sum(self.da_outputs['bsu'].get((r, b, t), 0) for b in range(1, 4))\n",
    "                               for t in range(1, 25)})\n",
    "            \n",
    "            fo_down = pd.Series({t: sum(self.da_outputs['hsd'].get((r, g, t), 0) for g in range(1, 6)) + \n",
    "                                    sum(self.da_outputs['bsd'].get((r, b, t), 0) for b in range(1, 4))\n",
    "                                 for t in range(1, 25)})\n",
    "            \n",
    "            hourly_results[f'FO_up_tier_{r}'] = fo_up\n",
    "            hourly_results[f'FO_down_tier_{r}'] = fo_down\n",
    "        \n",
    "        return hourly_results\n",
    "    \n",
    "    def plot_hourly_results(self, hourly_results):\n",
    "        \"\"\"Plot key hourly results\"\"\"\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(12, 15))\n",
    "        \n",
    "        # Plot 1: Energy Prices\n",
    "        price_cols = [col for col in hourly_results.columns if 'price' in col.lower()]\n",
    "        hourly_results[price_cols].plot(ax=axes[0])\n",
    "        axes[0].set_title('Hourly Energy Prices')\n",
    "        axes[0].set_xlabel('Hour')\n",
    "        axes[0].set_ylabel('Price ($/MWh)')\n",
    "        axes[0].grid(True)\n",
    "        \n",
    "        # Plot 2: Generator and Storage Schedules\n",
    "        gen_cols = [col for col in hourly_results.columns if 'Gen_' in col]\n",
    "        storage_discharge = [col for col in hourly_results.columns if 'discharge' in col]\n",
    "        storage_charge = [col for col in hourly_results.columns if 'charge' in col]\n",
    "        \n",
    "        hourly_results[gen_cols + storage_discharge].plot(ax=axes[1])\n",
    "        # Plot storage charging as negative values\n",
    "        (-1 * hourly_results[storage_charge]).plot(ax=axes[1], linestyle='--')\n",
    "        \n",
    "        axes[1].set_title('Hourly Generation and Storage Schedules')\n",
    "        axes[1].set_xlabel('Hour')\n",
    "        axes[1].set_ylabel('Power (MW)')\n",
    "        axes[1].grid(True)\n",
    "        \n",
    "        # Plot 3: FO Volumes\n",
    "        fo_up_cols = [col for col in hourly_results.columns if 'FO_up_tier' in col]\n",
    "        fo_down_cols = [col for col in hourly_results.columns if 'FO_down_tier' in col]\n",
    "        \n",
    "        hourly_results[fo_up_cols].plot(ax=axes[2])\n",
    "        (-1 * hourly_results[fo_down_cols]).plot(ax=axes[2], linestyle='--')\n",
    "        \n",
    "        axes[2].set_title('Hourly Flexibility Option Volumes')\n",
    "        axes[2].set_xlabel('Hour')\n",
    "        axes[2].set_ylabel('FO Volume (MW)')\n",
    "        axes[2].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('hourly_results.png')\n",
    "        plt.show()\n",
    "        \n",
    "    def calculate_revenues_costs(self):\n",
    "        \"\"\"Calculate revenues and costs for all participants\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Initialize dictionaries for each participant type\n",
    "        generator_results = {g: {} for g in range(1, 6)}\n",
    "        storage_results = {b: {} for b in range(1, 4)}\n",
    "        \n",
    "        try:\n",
    "            # Calculate DA energy revenues/costs for generators\n",
    "            for g in range(1, 6):\n",
    "                # DA energy revenues\n",
    "                da_energy_revenue = sum(self.da_outputs['DA_price'][t] * self.da_outputs['xDA'].get((g, t), 0) \n",
    "                                        for t in range(1, 25))\n",
    "                \n",
    "                # DA FO premiums\n",
    "                da_fo_up_revenue = sum(\n",
    "                    self.da_outputs['FO_up_price'].get((r, t), 0) * self.da_outputs['hsu'].get((r, g, t), 0)\n",
    "                    for r in range(1, 5) for t in range(1, 25)\n",
    "                )\n",
    "                \n",
    "                da_fo_down_revenue = sum(\n",
    "                    self.da_outputs['FO_down_price'].get((r, t), 0) * self.da_outputs['hsd'].get((r, g, t), 0)\n",
    "                    for r in range(1, 5) for t in range(1, 25)\n",
    "                )\n",
    "                \n",
    "                # RT adjustments\n",
    "                rt_revenue = {}\n",
    "                for s in range(1, 6):\n",
    "                    rt_revenue[s] = sum(\n",
    "                        self.rt_outputs['RT_price'].get((s, t), 0) * (\n",
    "                            self.rt_outputs['xup'].get((s, g, t), 0) - self.rt_outputs['xdn'].get((s, g, t), 0)\n",
    "                        ) for t in range(1, 25)\n",
    "                    )\n",
    "                \n",
    "                # Total revenues\n",
    "                generator_results[g]['DA_energy_revenue'] = da_energy_revenue\n",
    "                generator_results[g]['DA_FO_up_revenue'] = da_fo_up_revenue\n",
    "                generator_results[g]['DA_FO_down_revenue'] = da_fo_down_revenue\n",
    "                generator_results[g]['RT_revenue'] = rt_revenue\n",
    "                generator_results[g]['Total_revenue'] = da_energy_revenue + da_fo_up_revenue + da_fo_down_revenue + sum(rt_revenue.values()) / len(rt_revenue)\n",
    "            \n",
    "            # Calculate DA energy revenues/costs for storage units\n",
    "            for b in range(1, 4):\n",
    "                # DA energy revenues (discharge - charge)\n",
    "                da_energy_revenue = sum(\n",
    "                    self.da_outputs['DA_price'][t] * (\n",
    "                        self.da_outputs['p_dch_DA'].get((b, t), 0) - self.da_outputs['p_ch_DA'].get((b, t), 0)\n",
    "                    ) for t in range(1, 25)\n",
    "                )\n",
    "                \n",
    "                # DA FO premiums\n",
    "                da_fo_up_revenue = sum(\n",
    "                    self.da_outputs['FO_up_price'].get((r, t), 0) * self.da_outputs['bsu'].get((r, b, t), 0)\n",
    "                    for r in range(1, 5) for t in range(1, 25)\n",
    "                )\n",
    "                \n",
    "                da_fo_down_revenue = sum(\n",
    "                    self.da_outputs['FO_down_price'].get((r, t), 0) * self.da_outputs['bsd'].get((r, b, t), 0)\n",
    "                    for r in range(1, 5) for t in range(1, 25)\n",
    "                )\n",
    "                \n",
    "                # RT adjustments\n",
    "                rt_revenue = {}\n",
    "                for s in range(1, 6):\n",
    "                    rt_revenue[s] = sum(\n",
    "                        self.rt_outputs['RT_price'].get((s, t), 0) * (\n",
    "                            self.rt_outputs['p_dch_RT'].get((s, b, t), 0) - self.rt_outputs['p_ch_RT'].get((s, b, t), 0)\n",
    "                        ) for t in range(1, 25)\n",
    "                    )\n",
    "                \n",
    "                # Storage operation costs\n",
    "                storage_cost = sum(\n",
    "                    self.da_outputs.get('STORAGE_COST', {}).get(b, 5.0) * (\n",
    "                        self.da_outputs['p_ch_DA'].get((b, t), 0) + self.da_outputs['p_dch_DA'].get((b, t), 0)\n",
    "                    ) for t in range(1, 25)\n",
    "                )\n",
    "                \n",
    "                # Total revenues\n",
    "                storage_results[b]['DA_energy_revenue'] = da_energy_revenue\n",
    "                storage_results[b]['DA_FO_up_revenue'] = da_fo_up_revenue\n",
    "                storage_results[b]['DA_FO_down_revenue'] = da_fo_down_revenue\n",
    "                storage_results[b]['RT_revenue'] = rt_revenue\n",
    "                storage_results[b]['Storage_cost'] = storage_cost\n",
    "                storage_results[b]['Total_revenue'] = da_energy_revenue + da_fo_up_revenue + da_fo_down_revenue + sum(rt_revenue.values()) / len(rt_revenue) - storage_cost\n",
    "            \n",
    "            # Combine results\n",
    "            results['generators'] = generator_results\n",
    "            results['storage'] = storage_results\n",
    "            \n",
    "            # Calculate system costs\n",
    "            system_costs = {\n",
    "                'DA_cost': self.da_outputs.get('total_cost', 0),\n",
    "                'RT_cost': sum(self.rt_outputs.get('scenario_costs', {}).values()),\n",
    "                'Total_cost': self.da_outputs.get('total_cost', 0) + sum(self.rt_outputs.get('scenario_costs', {}).values())\n",
    "            }\n",
    "            results['system'] = system_costs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating revenues and costs: {str(e)}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def summarize_fo_effectiveness(self):\n",
    "        \"\"\"Analyze and summarize the effectiveness of FOs\"\"\"\n",
    "        summary = {}\n",
    "        \n",
    "        try:\n",
    "            # Calculate total FO volumes by hour and tier\n",
    "            fo_volumes = pd.DataFrame(index=range(1, 25))\n",
    "            \n",
    "            # Sum up FO volumes from generators and storage\n",
    "            for r in range(1, 5):\n",
    "                up_vol = []\n",
    "                down_vol = []\n",
    "                \n",
    "                for t in range(1, 25):\n",
    "                    # Generator FO volumes\n",
    "                    gen_up = sum(self.da_outputs['hsu'].get((r, g, t), 0) for g in range(1, 6))\n",
    "                    gen_down = sum(self.da_outputs['hsd'].get((r, g, t), 0) for g in range(1, 6))\n",
    "                    \n",
    "                    # Storage FO volumes\n",
    "                    storage_up = sum(self.da_outputs['bsu'].get((r, b, t), 0) for b in range(1, 4))\n",
    "                    storage_down = sum(self.da_outputs['bsd'].get((r, b, t), 0) for b in range(1, 4))\n",
    "                    \n",
    "                    up_vol.append(gen_up + storage_up)\n",
    "                    down_vol.append(gen_down + storage_down)\n",
    "                \n",
    "                fo_volumes[f'Up_Tier_{r}'] = up_vol\n",
    "                fo_volumes[f'Down_Tier_{r}'] = down_vol\n",
    "            \n",
    "            # Calculate average FO prices by tier\n",
    "            fo_prices = {}\n",
    "            for r in range(1, 5):\n",
    "                up_price = np.mean([self.da_outputs['FO_up_price'].get((r, t), 0) for t in range(1, 25)])\n",
    "                down_price = np.mean([self.da_outputs['FO_down_price'].get((r, t), 0) for t in range(1, 25)])\n",
    "                \n",
    "                fo_prices[f'Up_Tier_{r}'] = up_price\n",
    "                fo_prices[f'Down_Tier_{r}'] = down_price\n",
    "            \n",
    "            # Calculate price convergence between DA and RT markets\n",
    "            da_prices = pd.Series(self.da_outputs.get('DA_price', {}))\n",
    "            rt_avg_prices = pd.Series({\n",
    "                t: np.mean([self.rt_outputs['RT_price'].get((s, t), 0) for s in range(1, 6)])\n",
    "                for t in range(1, 25)\n",
    "            })\n",
    "            \n",
    "            price_diff = (da_prices - rt_avg_prices).abs()\n",
    "            price_convergence = {\n",
    "                'mean_abs_diff': price_diff.mean(),\n",
    "                'max_abs_diff': price_diff.max(),\n",
    "                'price_diff_by_hour': price_diff.to_dict()\n",
    "            }\n",
    "            \n",
    "            # Calculate FO exercise rates in RT\n",
    "            fo_exercise = {}\n",
    "            for r in range(1, 5):\n",
    "                up_exercise = {}\n",
    "                down_exercise = {}\n",
    "                \n",
    "                for t in range(1, 25):\n",
    "                    up_vol = sum(self.da_outputs['hsu'].get((r, g, t), 0) for g in range(1, 6)) + \\\n",
    "                             sum(self.da_outputs['bsu'].get((r, b, t), 0) for b in range(1, 4))\n",
    "                    \n",
    "                    down_vol = sum(self.da_outputs['hsd'].get((r, g, t), 0) for g in range(1, 6)) + \\\n",
    "                               sum(self.da_outputs['bsd'].get((r, b, t), 0) for b in range(1, 4))\n",
    "                    \n",
    "                    # Calculate RT exercise counts\n",
    "                    up_count = 0\n",
    "                    down_count = 0\n",
    "                    \n",
    "                    for s in range(1, 6):\n",
    "                        # Check if FO is exercised in scenario s\n",
    "                        # For up FO: RT price > strike price and scenario <= tier\n",
    "                        # For down FO: RT price < strike price and scenario > tier\n",
    "                        \n",
    "                        if s <= r and up_vol > 0:\n",
    "                            up_count += 1\n",
    "                        \n",
    "                        if s > r and down_vol > 0:\n",
    "                            down_count += 1\n",
    "                    \n",
    "                    if up_vol > 0:\n",
    "                        up_exercise[t] = up_count / 5  # Normalize by scenario count\n",
    "                    \n",
    "                    if down_vol > 0:\n",
    "                        down_exercise[t] = down_count / 5  # Normalize by scenario count\n",
    "                \n",
    "                fo_exercise[f'Up_Tier_{r}'] = up_exercise\n",
    "                fo_exercise[f'Down_Tier_{r}'] = down_exercise\n",
    "            \n",
    "            # Combine results\n",
    "            summary['fo_volumes'] = fo_volumes\n",
    "            summary['fo_prices'] = fo_prices\n",
    "            summary['price_convergence'] = price_convergence\n",
    "            summary['fo_exercise'] = fo_exercise\n",
    "            \n",
    "            # Calculate storage contribution to FO\n",
    "            storage_fo_contribution = {}\n",
    "            for r in range(1, 5):\n",
    "                storage_up = sum(sum(self.da_outputs['bsu'].get((r, b, t), 0) for b in range(1, 4)) \n",
    "                                 for t in range(1, 25))\n",
    "                \n",
    "                total_up = storage_up + sum(sum(self.da_outputs['hsu'].get((r, g, t), 0) for g in range(1, 6)) \n",
    "                                           for t in range(1, 25))\n",
    "                \n",
    "                storage_down = sum(sum(self.da_outputs['bsd'].get((r, b, t), 0) for b in range(1, 4)) \n",
    "                                   for t in range(1, 25))\n",
    "                \n",
    "                total_down = storage_down + sum(sum(self.da_outputs['hsd'].get((r, g, t), 0) for g in range(1, 6)) \n",
    "                                               for t in range(1, 25))\n",
    "                \n",
    "                if total_up > 0:\n",
    "                    storage_fo_contribution[f'Up_Tier_{r}'] = storage_up / total_up\n",
    "                else:\n",
    "                    storage_fo_contribution[f'Up_Tier_{r}'] = 0\n",
    "                \n",
    "                if total_down > 0:\n",
    "                    storage_fo_contribution[f'Down_Tier_{r}'] = storage_down / total_down\n",
    "                else:\n",
    "                    storage_fo_contribution[f'Down_Tier_{r}'] = 0\n",
    "            \n",
    "            summary['storage_fo_contribution'] = storage_fo_contribution\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing FO effectiveness: {str(e)}\")\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def plot_fo_volumes_prices(self, fo_summary):\n",
    "        \"\"\"Plot FO volumes and prices by tier\"\"\"\n",
    "        if not fo_summary or 'fo_volumes' not in fo_summary or 'fo_prices' not in fo_summary:\n",
    "            print(\"Insufficient data for plotting\")\n",
    "            return\n",
    "        \n",
    "        # Get FO volumes\n",
    "        fo_volumes = fo_summary['fo_volumes']\n",
    "        fo_prices = fo_summary['fo_prices']\n",
    "        \n",
    "        # Create figure\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Plot Up FO volumes\n",
    "        up_cols = [col for col in fo_volumes.columns if 'Up_' in col]\n",
    "        fo_volumes[up_cols].plot(ax=axes[0, 0], marker='o')\n",
    "        axes[0, 0].set_title('Upward FO Volumes by Tier')\n",
    "        axes[0, 0].set_xlabel('Hour')\n",
    "        axes[0, 0].set_ylabel('FO Volume (MW)')\n",
    "        axes[0, 0].grid(True)\n",
    "        \n",
    "        # Plot Down FO volumes\n",
    "        down_cols = [col for col in fo_volumes.columns if 'Down_' in col]\n",
    "        fo_volumes[down_cols].plot(ax=axes[0, 1], marker='o')\n",
    "        axes[0, 1].set_title('Downward FO Volumes by Tier')\n",
    "        axes[0, 1].set_xlabel('Hour')\n",
    "        axes[0, 1].set_ylabel('FO Volume (MW)')\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        # Plot Up FO prices\n",
    "        up_prices = pd.Series({int(k.split('_')[-1]): v for k, v in fo_prices.items() if 'Up_' in k})\n",
    "        up_prices.plot(kind='bar', ax=axes[1, 0])\n",
    "        axes[1, 0].set_title('Upward FO Prices by Tier')\n",
    "        axes[1, 0].set_xlabel('Tier')\n",
    "        axes[1, 0].set_ylabel('FO Price ($/MW)')\n",
    "        axes[1, 0].grid(True)\n",
    "        \n",
    "        # Plot Down FO prices\n",
    "        down_prices = pd.Series({int(k.split('_')[-1]): v for k, v in fo_prices.items() if 'Down_' in k})\n",
    "        down_prices.plot(kind='bar', ax=axes[1, 1])\n",
    "        axes[1, 1].set_title('Downward FO Prices by Tier')\n",
    "        axes[1, 1].set_xlabel('Tier')\n",
    "        axes[1, 1].set_ylabel('FO Price ($/MW)')\n",
    "        axes[1, 1].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('fo_volumes_prices.png')\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_storage_contribution(self, fo_summary):\n",
    "        \"\"\"Plot storage contribution to FO by tier\"\"\"\n",
    "        if not fo_summary or 'storage_fo_contribution' not in fo_summary:\n",
    "            print(\"Insufficient data for plotting\")\n",
    "            return\n",
    "        \n",
    "        # Get storage contribution data\n",
    "        storage_contrib = fo_summary['storage_fo_contribution']\n",
    "        \n",
    "        # Create figure\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        # Prepare data for plotting\n",
    "        tiers = sorted(list(set([int(k.split('_')[-1]) for k in storage_contrib.keys()])))\n",
    "        up_contrib = [storage_contrib.get(f'Up_Tier_{r}', 0) * 100 for r in tiers]\n",
    "        down_contrib = [storage_contrib.get(f'Down_Tier_{r}', 0) * 100 for r in tiers]\n",
    "        \n",
    "        # Create bar plot\n",
    "        x = np.arange(len(tiers))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, up_contrib, width, label='Upward FO')\n",
    "        ax.bar(x + width/2, down_contrib, width, label='Downward FO')\n",
    "        \n",
    "        ax.set_xlabel('Tier')\n",
    "        ax.set_ylabel('Storage Contribution (%)')\n",
    "        ax.set_title('Storage Contribution to Flexibility Options by Tier')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([f'Tier {r}' for r in tiers])\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('storage_contribution.png')\n",
    "        plt.show()\n",
    "        \n",
    "    def export_results(self, filename='fo_results.xlsx'):\n",
    "        \"\"\"Export results to Excel file\"\"\"\n",
    "        try:\n",
    "            with pd.ExcelWriter(filename) as writer:\n",
    "                # Export hourly results\n",
    "                hourly_results = self.hourly_analysis()\n",
    "                hourly_results.to_excel(writer, 'Hourly_Results')\n",
    "                \n",
    "                # Export revenue/cost results\n",
    "                rev_cost = self.calculate_revenues_costs()\n",
    "                \n",
    "                # Generator revenues\n",
    "                gen_rev = pd.DataFrame()\n",
    "                for g, values in rev_cost.get('generators', {}).items():\n",
    "                    for key, value in values.items():\n",
    "                        if key != 'RT_revenue':\n",
    "                            gen_rev.loc[f'Generator_{g}', key] = value\n",
    "                        else:\n",
    "                            for s, rev in value.items():\n",
    "                                gen_rev.loc[f'Generator_{g}', f'RT_revenue_sc{s}'] = rev\n",
    "                \n",
    "                gen_rev.to_excel(writer, 'Generator_Revenues')\n",
    "                \n",
    "                # Storage revenues\n",
    "                storage_rev = pd.DataFrame()\n",
    "                for b, values in rev_cost.get('storage', {}).items():\n",
    "                    for key, value in values.items():\n",
    "                        if key != 'RT_revenue':\n",
    "                            storage_rev.loc[f'Storage_{b}', key] = value\n",
    "                        else:\n",
    "                            for s, rev in value.items():\n",
    "                                storage_rev.loc[f'Storage_{b}', f'RT_revenue_sc{s}'] = rev\n",
    "                \n",
    "                storage_rev.to_excel(writer, 'Storage_Revenues')\n",
    "                \n",
    "                # System costs\n",
    "                system_costs = pd.Series(rev_cost.get('system', {}))\n",
    "                system_costs.to_frame('Value').to_excel(writer, 'System_Costs')\n",
    "                \n",
    "                # FO effectiveness summary\n",
    "                fo_summary = self.summarize_fo_effectiveness()\n",
    "                \n",
    "                # FO volumes\n",
    "                if 'fo_volumes' in fo_summary:\n",
    "                    fo_summary['fo_volumes'].to_excel(writer, 'FO_Volumes')\n",
    "                \n",
    "                # FO prices\n",
    "                if 'fo_prices' in fo_summary:\n",
    "                    pd.Series(fo_summary['fo_prices']).to_frame('Value').to_excel(writer, 'FO_Prices')\n",
    "                \n",
    "                # Price convergence\n",
    "                if 'price_convergence' in fo_summary:\n",
    "                    price_conv = fo_summary['price_convergence']\n",
    "                    pd.Series({\n",
    "                        'Mean_Abs_Diff': price_conv.get('mean_abs_diff', 0),\n",
    "                        'Max_Abs_Diff': price_conv.get('max_abs_diff', 0)\n",
    "                    }).to_frame('Value').to_excel(writer, 'Price_Convergence')\n",
    "                    \n",
    "                    pd.Series(price_conv.get('price_diff_by_hour', {})).to_frame('Value').to_excel(writer, 'Price_Diff_By_Hour')\n",
    "                \n",
    "                # Storage contribution\n",
    "                if 'storage_fo_contribution' in fo_summary:\n",
    "                    pd.Series(fo_summary['storage_fo_contribution']).to_frame('Value').to_excel(writer, 'Storage_Contribution')\n",
    "                \n",
    "            print(f\"Results exported to {filename}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error exporting results: {str(e)}\")\n",
    "    \n",
    "    def run_full_analysis(self):\n",
    "        \"\"\"Run complete analysis and generate all plots\"\"\"\n",
    "        # Perform hourly analysis\n",
    "        hourly_results = self.hourly_analysis()\n",
    "        self.plot_hourly_results(hourly_results)\n",
    "        \n",
    "        # Calculate revenues and costs\n",
    "        rev_cost = self.calculate_revenues_costs()\n",
    "        \n",
    "        # Analyze FO effectiveness\n",
    "        fo_summary = self.summarize_fo_effectiveness()\n",
    "        self.plot_fo_volumes_prices(fo_summary)\n",
    "        self.plot_storage_contribution(fo_summary)\n",
    "        \n",
    "        # Export results\n",
    "        self.export_results()\n",
    "        \n",
    "        return {\n",
    "            'hourly_results': hourly_results,\n",
    "            'rev_cost': rev_cost,\n",
    "            'fo_summary': fo_summary\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Flexibility Options with Storage Analysis...\n",
      "Data processor initialized.\n",
      "Data preparation completed.\n",
      "Model solver initialized.\n",
      "\n",
      "Solving DA model with Flexibility Options...\n",
      "ERROR: Constructing component 'VC' from data={1: 20.0, 2: 30.0, 3: 40.0, 4:\n",
      "50.0, 5: 60.0} failed:\n",
      "        RuntimeError: Failed to set value for param=VC, index=1, value=20.0.\n",
      "    \tsource error message=\"Index '1' is not valid for indexed component 'VC'\"\n",
      "Error in DA model: Failed to set value for param=VC, index=1, value=20.0.\n",
      "\tsource error message=\"Index '1' is not valid for indexed component 'VC'\"\n",
      "ERROR: DA model solution failed. Exiting...\n"
     ]
    }
   ],
   "source": [
    "input_file = '2.csv'\n",
    "output_dir = 'Flexibility_Options_Results'\n",
    "solver_path = 'C:/Program Files/IBM/ILOG/CPLEX_Studio_Community2212/cplex/bin/x64_win64/cplex'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the full workflow\"\"\"\n",
    "    try:\n",
    "        print(\"Starting Flexibility Options with Storage Analysis...\")\n",
    "        \n",
    "        # Initialize data processor\n",
    "        processor = DataProcessor(input_file)\n",
    "        print(\"Data processor initialized.\")\n",
    "        \n",
    "        # Prepare DA and RT data\n",
    "        da_data = processor.prepare_da_data()\n",
    "        rt_data = processor.prepare_rt_data()\n",
    "        print(\"Data preparation completed.\")\n",
    "        \n",
    "        # Initialize model solver\n",
    "        solver = ModelSolver(solver_path)\n",
    "        if solver.opt is None:\n",
    "            print(\"ERROR: Solver initialization failed. Exiting...\")\n",
    "            return\n",
    "        print(\"Model solver initialized.\")\n",
    "        \n",
    "        # Solve DA model\n",
    "        print(\"\\nSolving DA model with Flexibility Options...\")\n",
    "        da_instance, da_outputs = solver.solve_da_model(da_data)\n",
    "        \n",
    "        if da_instance is None or da_outputs is None:\n",
    "            print(\"ERROR: DA model solution failed. Exiting...\")\n",
    "            return\n",
    "        print(\"DA model solved successfully.\")\n",
    "        \n",
    "        # Solve RT model\n",
    "        print(\"\\nSolving RT model for each scenario...\")\n",
    "        rt_instance, rt_outputs = solver.solve_rt_model(rt_data, da_outputs)\n",
    "        \n",
    "        if rt_instance is None or rt_outputs is None:\n",
    "            print(\"ERROR: RT model solution failed. Exiting...\")\n",
    "            return\n",
    "        print(\"RT model solved successfully.\")\n",
    "        \n",
    "        # Analyze results\n",
    "        print(\"\\nAnalyzing results...\")\n",
    "        analyzer = ResultsAnalyzer(da_outputs, rt_outputs)\n",
    "        analysis_results = analyzer.run_full_analysis()\n",
    "        print(\"Analysis completed and visualizations generated.\")\n",
    "        \n",
    "        # Export key model outputs for further analysis\n",
    "        export_model_outputs(da_instance, rt_instance, os.path.join(output_dir, 'model_outputs.xlsx'))\n",
    "        print(f\"Model outputs exported to {os.path.join(output_dir, 'model_outputs.xlsx')}\")\n",
    "        \n",
    "        print(\"\\nSummary:\")\n",
    "        print(f\"- Total DA cost: ${da_outputs.get('total_cost', 0):.2f}\")\n",
    "        \n",
    "        if analysis_results and 'fo_summary' in analysis_results and 'storage_fo_contribution' in analysis_results['fo_summary']:\n",
    "            storage_contrib = analysis_results['fo_summary']['storage_fo_contribution']\n",
    "            avg_storage_contrib = np.mean([v for k, v in storage_contrib.items()]) * 100\n",
    "            print(f\"- Average storage contribution to FOs: {avg_storage_contrib:.2f}%\")\n",
    "        \n",
    "        print(f\"- Full results available in: {output_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {str(e)}\")\n",
    "\n",
    "def export_model_outputs(da_instance, rt_instance, filename):\n",
    "    \"\"\"Export raw model outputs for further analysis\"\"\"\n",
    "    try:\n",
    "        with pd.ExcelWriter(filename) as writer:\n",
    "            # Export dual variables from DA model\n",
    "            da_duals = {}\n",
    "            for c in da_instance.component_objects(pyo.Constraint, active=True):\n",
    "                for idx in c:\n",
    "                    if idx in da_instance.dual:\n",
    "                        da_duals[f\"{c.name}_{idx}\"] = da_instance.dual[idx]\n",
    "            \n",
    "            pd.Series(da_duals).to_frame('Value').to_excel(writer, 'DA_Duals')\n",
    "            \n",
    "            # Export storage-related variables from DA model\n",
    "            storage_vars = {}\n",
    "            for v_name in ['e', 'p_ch', 'p_dch', 'bsu', 'bsd']:\n",
    "                if hasattr(da_instance, v_name):\n",
    "                    v = getattr(da_instance, v_name)\n",
    "                    for idx in v:\n",
    "                        storage_vars[f\"{v_name}_{idx}\"] = v[idx].value\n",
    "            \n",
    "            pd.Series(storage_vars).to_frame('Value').to_excel(writer, 'DA_Storage_Variables')\n",
    "            \n",
    "            # Export RT energy prices\n",
    "            if hasattr(rt_instance, 'dual'):\n",
    "                rt_prices = {}\n",
    "                for s in rt_instance.S:\n",
    "                    for t in rt_instance.T:\n",
    "                        if hasattr(rt_instance, 'Con3') and (s, t) in rt_instance.Con3:\n",
    "                            if (s, t) in rt_instance.dual:\n",
    "                                rt_prices[f\"RT_price_s{s}_t{t}\"] = rt_instance.dual[(s, t)]\n",
    "                \n",
    "                pd.Series(rt_prices).to_frame('Value').to_excel(writer, 'RT_Prices')\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting model outputs: {str(e)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating visualizations: [Errno 2] No such file or directory: 'Test_output_files/Results_SectionV\\\\Summary_Results_2025_02_27.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_summary_results(summary_file):\n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        system_cost = pd.read_excel(summary_file, sheet_name='System_Cost', index_col=0)\n",
    "        price_conv = pd.read_excel(summary_file, sheet_name='Price_Convergence', index_col=0)\n",
    "        premium_up = pd.read_excel(summary_file, sheet_name='Premium_Up', index_col=0)\n",
    "        premium_down = pd.read_excel(summary_file, sheet_name='Premium_Down', index_col=0)\n",
    "        demand_cost = pd.read_excel(summary_file, sheet_name='Demand_Cost', index_col=0)\n",
    "        curtail_cost = pd.read_excel(summary_file, sheet_name='Curtailment_Cost', index_col=0)\n",
    "        \n",
    "        # Check if dataframes contain numeric data\n",
    "        if (system_cost.empty or price_conv.empty or premium_up.empty or \n",
    "            premium_down.empty or demand_cost.empty or curtail_cost.empty):\n",
    "            print(\"Error: One or more sheets contain no data\")\n",
    "            return\n",
    "            \n",
    "        # Convert data to numeric, replacing non-numeric values with NaN\n",
    "        system_cost = system_cost.apply(pd.to_numeric, errors='coerce')\n",
    "        price_conv = price_conv.apply(pd.to_numeric, errors='coerce')\n",
    "        premium_up = premium_up.apply(pd.to_numeric, errors='coerce')\n",
    "        premium_down = premium_down.apply(pd.to_numeric, errors='coerce')\n",
    "        demand_cost = demand_cost.apply(pd.to_numeric, errors='coerce')\n",
    "        curtail_cost = curtail_cost.apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(15, 15))\n",
    "        fig.suptitle('Summary Results Visualization')\n",
    "        \n",
    "        # Plot system cost\n",
    "        if not system_cost.empty and system_cost.notna().any().any():\n",
    "            system_cost.plot(kind='bar', ax=axes[0,0], title='System Cost')\n",
    "            axes[0,0].set_ylabel('Cost')\n",
    "            axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            axes[0,0].set_title('System Cost - No numeric data available')\n",
    "        \n",
    "        # Plot price convergence\n",
    "        if not price_conv.empty and price_conv.notna().any().any():\n",
    "            price_conv.plot(kind='bar', ax=axes[0,1], title='Price Convergence')\n",
    "            axes[0,1].set_ylabel('Price')\n",
    "            axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            axes[0,1].set_title('Price Convergence - No numeric data available')\n",
    "        \n",
    "        # Plot premium up/down\n",
    "        if not premium_up.empty and premium_up.notna().any().any():\n",
    "            premium_up.plot(kind='bar', ax=axes[1,0], title='Premium Up')\n",
    "            axes[1,0].set_ylabel('Premium')\n",
    "            axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            axes[1,0].set_title('Premium Up - No numeric data available')\n",
    "        \n",
    "        if not premium_down.empty and premium_down.notna().any().any():\n",
    "            premium_down.plot(kind='bar', ax=axes[1,1], title='Premium Down')\n",
    "            axes[1,1].set_ylabel('Premium')\n",
    "            axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            axes[1,1].set_title('Premium Down - No numeric data available')\n",
    "        \n",
    "        # Plot demand and curtailment costs\n",
    "        if not demand_cost.empty and demand_cost.notna().any().any():\n",
    "            demand_cost.plot(kind='bar', ax=axes[2,0], title='Demand Cost')\n",
    "            axes[2,0].set_ylabel('Cost')\n",
    "            axes[2,0].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            axes[2,0].set_title('Demand Cost - No numeric data available')\n",
    "        \n",
    "        if not curtail_cost.empty and curtail_cost.notna().any().any():\n",
    "            curtail_cost.plot(kind='bar', ax=axes[2,1], title='Curtailment Cost')\n",
    "            axes[2,1].set_ylabel('Cost')\n",
    "            axes[2,1].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            axes[2,1].set_title('Curtailment Cost - No numeric data available')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating visualizations: {str(e)}\")\n",
    "\n",
    "# Example usage for visualization\n",
    "if __name__ == \"__main__\":\n",
    "    summary_file = os.path.join('Test_output_files/Results_SectionV', f\"Summary_Results_{date.today().strftime('%Y_%m_%d')}.xlsx\")\n",
    "    plot_summary_results(summary_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
